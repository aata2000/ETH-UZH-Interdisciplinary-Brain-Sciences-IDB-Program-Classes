\section{Lecture 1}
Adding neuroscience to explanations make explanations sound better to non-neuroscience novices.
Interestingly, the "seductive allure" study could not be replicated. 

\section{Lecture 2: Reward Learning Part I}
\subsection{Outline}
\begin{itemize}
    \item Classical Conditioning
    \item Instrumental conditioning
    \item Models explaining conditioning effects:
    \begin{itemize}
        \item Rescorla-Wagner
        \item Temporal Difference
    \end{itemize}
\end{itemize}

\subsection{Why Reward Learning}
\begin{itemize}
    \item A basic tenet of economics and other decision sciences is that preferences drive choices.
    \item Therefore, the formation of preferences is important to understanding decision making.
    \item We are not born knowing everything, so we have to learn our preferences.
\end{itemize}

\subsection{How do we learn about rewards and form preferences}
\begin{itemize}
    \item Often, when we talk about learning colloquially, we are referring to memorizing facts or procedures.
    \item Similar memory processes can be involved in reward learning.
    \item This lecture, however, will be based on implicit learning processes
\end{itemize}
\subsection{How do we learn about rewards and form preferences?}
\begin{itemize}
    \item The brain has evolved to learn about rewards and form preferences by pairing stimuli with those outcomes:
    \begin{itemize}
        \item The shape and smell of apples can be paired with sweet taste and nutrients
    \end{itemize}
    \item Once a pairing has been formed, an organism can respond to that stimuli.
\end{itemize}

\subsection{Stimulus associations}
\begin{itemize}
    \item Unconditioned stimulus leads way to unconditioned response.
    \item For example: A rat seeing a cat is an unconditioned stimulus. The rat freezing is the unconditioned response.
\end{itemize}

\subsection{Classical Conditioning}
\begin{itemize}
    \item Uses a conditioned stimulus to unconditioned stimulus pairing to study learning.
    \item The process of classical conditioning pairs new stimuli that have no automatic response with an unconditioned stimulus that has an automatic response.
    \item Aka Pavlovian conditioning.
\end{itemize}

\subsection{Pavlov's Experiments}
\begin{itemize}
    \item Pavlov was studying the digestive system. 
    \item They were measuring the saliva output in dogs. And they realized that dogs salivated right before food giving because footsteps towards the enclosure was paired with incoming food.
    \item Pavlov then ran this study by replacing footsteps with the sound of a bell, which is a very neutral sound.
    \item Dogs salivated with bells, as they paired the sound of the bell with incoming food, which was the reward.
\end{itemize}

\subsection{Terminology}
\begin{itemize}
    \item US:= Unconditioned stimulus
    \item UR:= Unconditioned response
    \item CS:= Conditioned stimulus
    \item CR:= Conditioned response
\end{itemize}

\subsection{Contingency not just contiguity}
It is not enough to have a CS and US occur with temporal contiguity, there must be a contingency between the CS and US such that P(US $\vert$ CS) $>$ P(US $\vert$ no CS)
\begin{itemize}
    \item Contiguity definition: the sequential occurrence or proximity of stimulus and response, causing their association in the mind.
    \item Contingency definition: 
Contingency theory proposes that for learning to take place, a stimulus must provide the subject information about the likelihood that certain events will occur.
\end{itemize}

\subsection{Types of classical conditioning}
\begin{itemize}
    \item Excitatory conditioning. Conditioned stimulus implies unconditioned stimulus, which results in conditioned response. Example: Pavlov
    \item Inhibitory conditioning: Conditioned stimulus implies the absence of unconditioned stimulus. Conditioned stimulus implies no conditioned response after training. For example, when you shine light and not show food, organism knows that light implies the absence of food. No salivation at all.
    \item Appetitive conditioning: US appetitive
    \begin{itemize}
        \item pair tone with food
    \end{itemize}
    \item Aversive conditioning: US aversive
    \begin{itemize}
        \item pair tone with an electric shock
    \end{itemize}
\end{itemize}

\subsection{Examples of 
excitatory conditioning}
\subsubsection{Simple motor responses: eye-blink conditioning}
\begin{itemize}
    \item Rabbit learns that a tone predicts a puff of air in the face and begins to blink when the tone is heard in the absence of air puffs.
    \item Note: Classical conditioning effects are tested in the absence of the unconditioned stimulus.
    \begin{itemize}
        \item This way we can be sure that it is the CS that produces the response and not the US.
    \end{itemize}
\end{itemize}

\subsubsection{Bodily functions can also be conditioned}
\begin{itemize}
    \item In rats, a US = electric shock triggers an UR = endorphin release, which induces analgesia. 
    \item Experiment: CS = tone, US = shock.
    \item Result: licking of wounded paw decreases in presence of tone (CS), meaning that the tone reduced the pain
    \item How?
    \begin{itemize}
        \item Lester and Fanselow show that the CS elicits the UR, endorphin release
        \item Their data show that the effect is reduced when rats injected with naltrexone, an opioid antagonist blocks the action of endorphins.
    \end{itemize}
\end{itemize}

\subsubsection{More complex motor responses in blue gourami (fish)
}
\begin{itemize}
    \item CS signals rival male $\rightarrow$ Bites and tail fighting increases
    \item CS signals presence of female $\rightarrow$ More courtship and appeasement behaviors
\end{itemize}

\subsubsection{Learning about hedonic utility: Taste preference learning}
\begin{itemize}
    \item Training
    \begin{itemize}
        \item Non-deprived (not hungry)
        \item Neutral Flavor 1 + sugar in water
        \item Neutral Flavor 2 in water
    \end{itemize}
    \item Test: Flavor 1 vs 2
    \begin{itemize}
        \item Non deprived vs deprived tested
    \end{itemize}
    \item In this case, US is sugar, UR is hedonic response, CR is measured indirectly through rat's consumption. Rat's state affects CS $\rightarrow$ CR relationship.
\end{itemize}
For non-deprived state, small mild preference for flavor 1, food deprived strong preference for flavor 1.
\begin{itemize}
    \item Done with extinction. Extinction means that the actual reward is not delivered for the test case. No sugar in the water in the test case.
    \item The rat learns to associate Flavor 1 with sugar
    \item Therefore, when in hungry sate, preference for Flavor 1 over Flavor 2 increases even though during the text stage neither mixture contains sugar.
\end{itemize}

\subsection{Open questions}
\begin{itemize}
    \item What is the range of bodily and neural processes that are capable of exhibiting classical conditioning?
    \item How much of learning in the brain can be thought of as an instance of classical conditioning?
\end{itemize}

\subsection{Evolutionary advantagegs and constraints on classical conditioning}
\subsection{Adaptiveness}
\begin{itemize}
    \item The US $\rightarrow$ URs are selected because they are adaptive
    \item In many settings, it is very useful to prepare the organism to a US by triggering the UR earlier.
    \item Example: Salivating in advance of food improves digestion.
\end{itemize}

\subsection{Example from the blue gourami experiment}
For example, in anticipation of female fish, increased courtship behavior also results in more offspring, which is
biologically advantageous

\subsection{Biological Preparedness}
\begin{itemize}
    \item Some CSs are more easily conditioned with particular CRs than others
    \item This reflects the evolutionary situation of the species
    \item Example: Tastes are more likely to be predictors of poisoning or nutrition than visual or auditory stimuli.
\end{itemize}

An example experiment:
\begin{itemize}
    \item Experiment 1: Thirsty rats: taste aversion learning paradigm
    \begin{itemize}
        \item Phase 1 (pre-test): Salty water consumption
        \item Phase 2 (shock): salty water $\Rightarrow$ shock
        \item Phase 3 (post-test): salty water consumption is measured
    \end{itemize}
\end{itemize}

Interesting conclusion: It is not possible to pair salty taste (CS) with shocks (US). However, there are some alternative explanations: maybe the salt concentration wasn't enough. Maybe rats don't learn tastes very well and this conclusion isn't a hint of biological preparedness. So here is a follow-up study:
\begin{itemize}
    \item Experiment 1: Thirsty rats: taste aversion learning paradigm
    \begin{itemize}
        \item Phase 1 (pre-test): Salty water consumption
        \item Phase 2 (shock): salty water $\Rightarrow$ illness (lithium chloride injection)
        \item Phase 3 (post-test): salty water consumption is measured
    \end{itemize}
\end{itemize}
With illness, rats very strongly preferred not drinking the salty water (aversion). However, one alternative explanation would be now that the shock wasn't enough in strength to influence the rats. So a third experiment is conducted as well to show that rats can learn from a shock as well.
\begin{itemize}
    \item Experiment 1: Thirsty rats: taste aversion learning paradigm
    \begin{itemize}
        \item Phase 1 (pre-test):  Light + tone 
        \item Phase 2 (shock or illness): 
        \begin{itemize}
            \item Group S: Light + tone $\Rightarrow$ shock
            \item Group I: Light + tone $\Rightarrow$ Illness
        \end{itemize}
        \item Phase 3 (post-test): salty water consumption is measured
    \end{itemize}
\end{itemize}
We concluded that rats are indeed receptive to shocks.

\subsection{Classical vs Instrumental Conditioning}
Instrumental conditioning works on similar principles as classical conditioning but often requires a specific action to get the reward.
\begin{itemize}
    \item Instrumental conditioning is very powerful and can be used to teach humans and animals to perform a wide variety of behaviors to earn rewards

\end{itemize}
\subsection{How are the CS-US associations learned}
\begin{itemize}
    \item How does the CS acquire or come to predict some value?
    \item Under what conditions does this occur?
\end{itemize}

\subsection{Rescorla-Wagner learning model}
\begin{itemize}
    \item V$_{t}$ = size (or value) of the US$_{t}$ predicted by the CS.
    \item U$_{t}$ = size (or value) of the US$_{t}$.
    \item $\alpha$ = learning rate. $\alpha$ $\in$ (0, 1) determines how much each trial impacts future predictions.
    \item V$_{t+1}$ = V$_{t}$ + $\alpha$(U$_{t}$ - V$_{t}$)
    \item If there are multiple CSs 1 - j: V$_{t+1}$ (i) = V$_{t}$(i) + $\alpha$(U$_{t}$ - $\sum$V$_{t}$(j))
    \item Intuition:
    \begin{itemize}
        \item Amount of learning is driven by magnitude of surprise
        \item Predictability attributed to a CS only if the US is not already predicted by other CSs
    \end{itemize}
\end{itemize}
$\alpha$ is the learning rate. However, having a high or low learning rate doesn't give you an inherent advantage. It should match the volatility of your environment instead.
\begin{itemize}
    \item This model makes several predictions that we can test:
    \begin{itemize}
        \item No learning without surprise or erros in prediction
        \item Learning reaches an asymptote when there is no more prediction error.
    \end{itemize}
\end{itemize}

\subsection{Predictions: asymptotic acquisition and extinction}
Eventually responses to a CS stabilize and no more additional CRs are give.
\\The curve is similar for extinction. As the tone is not paired with the airpuff initially, the rats still blink. But, as these are unpaired more and more, they asymptotically stop blinking.

\subsection{Blocking}
\begin{itemize}
    \item Phase 1: Some stimulus a $\rightarrow$ US
    \item Phase 2: A, B $\rightarrow$ US
    \item However, since B is identical in stimulus to A, in Phase 3 when we show B only, there is no element of surprise, hence, the response is the same.
\end{itemize}
\subsection{An interesting twist on blocking}
Blocking of learning for specific outcome is well documented, but what if the outcome isn't a specific event but the level of hedonic utility?

\subsection{Trans-reinforcer blocking}
Check the study on the powerpoint slide for this.

\subsection{Overshadowing}
\begin{itemize}
    \item Phase 1: A and B $\rightarrow$ US. Assume A is a bright light and B is a soft auditory tone.
    \item Test
    \item Results: Respond more to A than B as it was a stronger training stimulus.
\end{itemize}
The more salient stimulus will depend on the context and biological preparedness: 
\\Rats learn from taste and smell, pigeons from hearing. More weight put into the respective categories.

\subsection{Bottom Line}
Rescorla-Wagner can explain a sizable number of behavioral patterns in learning through
classical conditioning. However, there are some aspects that it cannot explain.

\subsection{Limitations of the Rescorla-Wagner Model}
You can update without experiencing the outcome. Wine example from class.

\subsection{Temporal Difference (TD) Learning}
\begin{itemize}
    \item Deals with continuous time rather than discrete trials consisting of stimulus + outcome
    \item Seeks to predict at each time point all future outcomes given current and previous stimuli
    V$_{t}$(X) = V$_{t-1}$(X) + $\alpha$(outcome(x$_{i}$)$_{t-1}$ + prediction(x$_{i}$)$_{t-1}$ - prediction(X)$_{t-2}$)
\end{itemize}

\subsection{Basic difference between TD and RW}
\begin{itemize}
    \item RW is discrete, TD is continuous.
    \item RW updates only when there is an outcome, TD updates whenever there is a change in the state of the world.
\end{itemize}

\subsection{Predictions of TD learning}
\begin{itemize}
    \item Can explain all previous predictions for RW.
    \item Also explains 2nd order conditioning.
\end{itemize}

\subsection{Second Order Conditioning}
\begin{itemize}
    \item Bell predicts food. And then you introduce a light that predicts the bell. Do you still salivate?
    \item The answer is yes. Organisms do learn that the light predicts the bell. TD learning incorporates stimuli with direct associations to reward and those that signal changes in the state of the world.
\end{itemize}

There is ample evidence that the brain uses this mechanism in reward learning.

\subsection{An Axiometic Formulation of the Reward Prediction Error Hypothesis}
\\Economists have developed an axiomatic model detailing the necessary and sufficient
conditions of a reward prediction error signal (Caplin and Dean 2008 QJE; Caplin et al.,
2010 QJE). The axiomatic predictions were subsequently tested with fMRI (Rutledge et al., 2010 J
Neuro). 

\subsection{Axioms for Reward Prediction Error Signals}
\begin{itemize}
    \item Axiom1: Consistent prize ordering
    \item Axiom 2: consistent lottery ordering
    \item Axiom 3: no-surprise equivalence
    \begin{itemize}
        \item Equivalence when there is no surprise
    \end{itemize}
\end{itemize}

\section{Reward Learning II}
\subsubsection{Dopamine neurons encode prediction error like signals}
\begin{itemize}
    \item Dopamine is a neurotransmitter
    \item Neurons that release dopamine can be found in the substantia nigra and ventral tegmental area and project to many other brain regions.
\end{itemize}
Single unit neuron recording: putting electrodes and recording their electrical activity individually

\subsection{TD learning and DA in nonhuman primates}
Monkeys were deprived of water and placed in front of a screen with electrodes in their brains and shown cues. Initially, juice was given only, without any cues, and dopaminergic neurons showed increased activity. Later, when the cue and the juice were paired, dopaminergic neurons fired at the conditioned stimulus, but not at the actual juice being delivered, as that was expected and there wasn't a prediction error. Later, a third run was made without the juice being given but a cue being signalled. In this case, CS does increase the firing rate of the dopaminergic neurons but the lack of juice later decreases it, as there is a prediction error.

\subsection{Schultz, Dayan, Montague (1997)}

\begin{itemize}
    \item Classic paper in neuroscience showing that midbrain dopamine neurons encode the qualitative predictions of the TD learning model
    \item Natural question: How well does the dopamine signal fit the quantitative predictions of the model?
    \begin{itemize}
        \item Error signals should scale with the amount of surprise about the outcome
    \end{itemize}
\end{itemize}

\subsection{DA signals do scale with surprise}
High surprise increases the firing rate more dramatically than medium high surprise. Prediction error is not binary, it tells us how much surprise as well.
\subsection{DA neurons also generate error signals for reward magnitude}
When cues imply different amounts of juice rewards, the more juice rewards yield much greater dopaminergic neuron firing rate.

\subsection{DA prediction error signals are context dependent}
Dopamine signals shouldn't be outcome signals and the results should always be dependent upon expectations. 
When all three cues are mixed, DA neuron firing is linear. However, a medium reward after many small rewards will give a larger signal than a medium reward after many larger rewards.
\subsection{Prediction error signals and dopamine neurons:
Human fMRI studies of reward learning}
We want to see if TD learning is monkey specific or if it applies to humans.

\subsection{Reward learning in humans} 
Normal events: You are in a fMRI scanner. A flash lights and six seconds later you are given juice.
\\Catch events: You are in a fMRI scanner. A flash lights and ten seconds later you are given a juice.
\\Once people notice that the light predicts the juice, people shouldn't make prediction errors after a while. However, in the test condition, when juice is not given, people can make a negative prediction error.

\\fMRI shows that when nothing is expected but juice is delivered, the signal change is stronger. 

\\The putamen in the brain gives the strongest responses, however, this isn't the area where the somas of the dopaminergic neurons reside, but instead, it is where they project.

\\Similarly, omission of juice when it is strongly expected shows a negative prediction error.
\subsection{Why are we talking about striatum in humans and VTA in monkeys}
It is technically difficult to measure neural activity in the substantia nigra or VTA with fMRI or EEG. Therefore, human studies of reward learning often focus on downstream targets of DA neurons.

\subsection{Measuring PE signals in human VTA}
This requires special MRI sequences that are linked to the person's heart and breathing rates. 
\\The point is that it is technically challenging and limits your availability to collect data from the rest of the brain.

\subsection{Human VTA does show prediction error signals}
With the same light desing, D'ardenne et. al 2008 showed that unexpected positive rewards showed a statistically significant change in activity, whereas the omitted reward conditioned also generated a response but wasn't statistically significant.
\subsection{Human striatum also shows prediction error signals}
This time, the omitted reward condition shows a statistically significant difference but the unexpected reward doesn't.

\subsection{VTA and striatum are correlated}
VTA := generator
\\Striatum := receiver

\subsection{VTA encodes PE for primary and secondary rewards}
\\Primary rewards include those that are necessary for the survival of species, such as food and sexual contact. Secondary rewards derive their value from primary rewards. 
\\Both the VTA and the striatum shows that the results can be generalized to secondary rewards like money and doesn't have to solely be useful in the condition of primary rewards.

\subsection{Summary so far}
\begin{itemize}
    \item BOLD activity in the ventral striatum seems to qualitatively encode for positive and negative PEs
    \item This fits well with monkey electrophysiology data since the vStr is a target of midbrain dopamine neurons 
    \item We can also show that human VTA encodes PE signals that correlate with the striatal signals
    \item Natural follow-up question: Does the BOLD activity in the striatum
encodes the PE quantitatively ?
\end{itemize}

\subsection{Striatal signals match quantiative predictions over time (learning)}
Definitions:
\begin{itemize}
    \item CS+: High probability of reward
    \item CSneut: High prob of neutral outcome
    \item CS-: High prob of negative outcome
\end{itemize}

\subsection{PE signals and DA neurons: Human fMRI studies of reward learning and choice}
\begin{itemize}
    \item So far we have been discussing passive learning paradigms
    \begin{itemize}
        \item The people have not been making any choices, only passively learning about stimulus-reward contingencies
        
    \end{itemize}
    \item This leads to the question, are the same systems involved in actual choices?
\end{itemize}

\subsection{PE and Instrumental learning}
\begin{itemize}
    \item In instrumental learning, the rewarding outcome is contingent upon a specific response.
    \item The ‘goodness’ or ‘badness’ of specific stimulus-action pairings is learned with repeated experience.
    \item Somewhat similar to classical or Pavlovian conditioning, except that the learner must make a response (i.e. must choose a certain action)
\end{itemize}
\subsection{PE signals for instrumental and classical conditioning}
Conclusion: Ventral striatum reflects PE signals for both types of conditioning

\subsection{Do neural reward learning systems show
evidence of behavioral phenomenon
associated with classical conditioning?}
\subsection{Blocking Paradigm}

\subsection{Neuroimaging Results}
The authors examine the BOLD signal in an independent ROI within the striatum from previous reward-learning study.
\\Seeing Y in extinction is associated with greater BOLD signal, consistent with ha positive prediction error.
\\Seeing X is associated with a decrease in BOLD signal. This is consistent with the fact that it does not predict the reward and is therefore bad news relative to A or Y, which are other symbols that they see in the task.

\subsection{Do learners and non-learners exhibit different PE signals in the striatum?}
Decks were either high paying or low paying. You had to learn which ones were High probability of winning decks and which ones were low probability of winning decks.

\subsection{Learners vs Non-learners}
For learners, a strong and robust correlation with PE signals whereas non-learners don't show the same correlation.
\subsection{When shouldn't you learn?}

\subsection{Learning with explicit instructions}
\begin{itemize}
    \item Humans often learn about costs and benefits through explicit instructions rather than trial and error.
    \item – Question: How do explicit and TD learning systems interact? What happens when they are in disagreement?

\end{itemize}
\subsection{Explicit vs experience learning}
Two conditions: Pure feedback vs instructed session. In pure feedback, we receive trial-by-trial feedback on the value of the green rectangle to try to predict its expected value. On the instructed run, we are given the probability of the anonymous variable being greater than 5. 

\\Unsurprisingly, subjects performed better in the instructed session. The instructed group was also less susceptable to trial-by-trial feedback.

\\PE like signals are also reduced in instructed sessions.

\\In the instructed session group, dorsal lateral Pre- Frontal Cortex activation was more compared to the feedback group. The dlPFC is associated with complex thinking and memory. dlPFC and vmPFC are inversely correlated.

\\Interpretation: Regions with access to the instructed knowledge suppress the trial-by-trial learning systems that rely on PE signals.

\subsection{Interim Summary}
Human and non-human primate brains express PE signals consistent with the implementation of TD algorithms during reward learning.
\\These TD learning systems aid learning when explicit knowledge is unavailable
\\However, these learning systems can be suppressed when explicit learning systems are available.

\subsection{Sample Exam Question}
Dopamine is a learning and motivation molecule, not a reward and pleasure molecule.

\subsection{Testing the RPE axioms}
Different gambling options were given to the subjects and they were asked to choose some.

\subsection{Standard regression analysis reveals ventral striatum activiy correlated with expected RPE signals}

\subsection{Testing the RPE axioms}
Tests of the magnitudes and slopes in ventral striatum show that activity there does not significantly deviate from the criteria laid out in the RPE axioms. Thus it satisfies the necessary and sufficient conditions for encoding an RPE signal.

\subsection{A word of caution on reverse inference from neuroimaging results
}
\begin{itemize}
    \item – We have discussed several studies where activity in portions of the striatum correlates with RPE signals. However, one should not infer that all striatal activity reflects RPEs.
    \item Most brain areas are involved in many different functions and one should always be cautious when making statements such as “There was activity in brain area A so the subject was thinking/feeling XYZ”
\end{itemize}

\subsection{An example of why caution is needed}
Basic motor functions are among the easiest, clearest, and most robust patterns of
activity that we can observe with fMRI. fMRI shows that both hand movement and imagined hand movement light up VERY similar areas in the brain.

\section{Lecture 4: Methods in Neuroeconomics}
\subsection{How can we measure brain activity}
\begin{itemize}
    \item Functional magnetic resonance imaging (fMRI)
    \item Positron emission tomography (PET)
    \item Magnetoencephalography (MEG): measures the magnetic changes due to currents.
    \item Electroencephalography (EEG): Measure electrical activity directly.
    \item Electrophysiological recordings. We don't use humans for obvious reasons but we use non-human primates or other organisms.
\end{itemize}

\subsection{How can we measure brain structure?}
\begin{itemize}
    \item Structural MRI
    \begin{itemize}
        \item Measure grey or white matter
        \begin{itemize}
            \item Grey matter = neurons
            \item White matter = glia cells and myelin
            
        \end{itemize}
    \end{itemize}
    \item Diffusion weighted imaging
    \begin{itemize}
        \item Primarily measures myelinated axons that convey neural signals between neurons
    \end{itemize}
\end{itemize}
We can measure the way water moves in diffusion tensor imaging to see which areas contain fibers, since white matter structures are impermeable to water, so the water goes around them.

\subsection{Brain Stimulation Methods}
\begin{itemize}
    \item Brain stimulation methods temporarilty alter brain acivity
    \item They do not measure brain activity, rather bbehavior is tested during or after stimulation.
\end{itemize}

\subsection{Brain Stimulation Methods}
\begin{itemize}
    \item Common techniques include:
    \begin{itemize}
        \item Transcranial Magnetic Stimulations (TMS)
        \item Transcranial Direct Current Stimulation (tDCS)
        \item Transcranial Altering Current Stimulation (tACS)
        \begin{itemize}
            \item Can be used to bring distant regions into or out of phase
        \end{itemize}
        \item Depp brain stimulation
        \begin{itemize}
            \item Implanted electrodes - most commonly as a treatment for Parkinson's Disease
        \end{itemize}
    \end{itemize}
\end{itemize}
\subsection{MRI Machine}
Creates a very strong magnetic field. 3 to 7 Teslas. You lie on your back, it is usually dark, loud, and there is a screen for Neuroeconomics studies.
You have to lie very still. You respond to questions on the screen using a button box under your fingers.
\subsection{Synopsis of MRI}
\begin{enumerate}
    \item Put subject in strong magnetic field
    \item Transmit radio waves into subject
    \item Turn off radio wave transmitter
    \item Receive radio waves re-transmitted by subject
    \item Convert measued radio frequency data into an image
\end{enumerate}
\subsection{MRI images are composed of voxels}
Voxels: 3D pixels
\\The resolution: 2-3 mm$^{2}$.
\subsection{Brain structure segmentation and measurement}
We can calculate what portion of the brain is white matter, grey matter, or CSF by calculating voxels.
\\Studies usually take raw images and segment it into only grey matter, only white matter, and only CSF image stacks.

\subsection{Cortical thickness from 5-22 years of age}
Typically grey matter density decreases from childhood to young adulthood and decreases most steeply from young adulthood to seniority.
\subsection{Association between grey matter and risk taking in the UK biobank}
Long term goal: how changes in biology is related to early life behavior. 
\\They are trying to see how grey matter volume is related to risk taking behavior. The more the grey matter density in certain regions (page 18 figure b), the less you are prone to taking risks.

\subsection{fMRI with Endogenous BOLD Contrast}
\begin{itemize}
    \item Blood Oxygenation Level Dependent Contrast
    \begin{itemize}
        \item We can measure changes in blood flow and oxygegnation levels with BOLD fMRI 
        \item Neural activity is associated with changes in blood flow and oxygen and nutrient consumption
        \item Changes in BOLD are a proxy for neural activity
    \end{itemize}
\end{itemize}
Neural activity is associated with changes in blood flow as a part of the brain that is working consumes more oxygen. It also overcompensates.
\subsection{BOLD fMRI as a vascular response}
\begin{itemize}
    \item Blood (hemoglobin) carries oxygen and glucose to the brain - and possesses different magnetic properties before and after neural consumption of oxygen.
    \item Hemoglobin exists in two states:
    \begin{itemize}
        \item HbO2 (oxyhemoglobin) has little effect the magnetic field
        \item Hb (deoxyhemoglobin) significantly effects local magnetism as it is attracted to the main magnetic field.
    \end{itemize}
\end{itemize}
This is good because we don't need to inject outside labels to create contrast.

\subsection{
What does the BOLD signal look like
}
\begin{itemize}
    \item A slow signal: increases about 2s after neural activity, plateaus around 6-8s, returns to baseline 8-11s after activity.

\end{itemize}
Note that the response is delayed. This slow response is the major drawback to fMRI as a research technique.
\\This is why we have to space out multiple tasks properly so that the BOLD signals don't overlap and interfere with one another.
\\If we want aggregate responses this might not be so bad; however, if you want individual responses, you have to space them out.
\subsection{fMRI analysis overview}
We want to look at fMRI images in two levels: First, we want to see the individual responses and then we want to aggregate responses between the individuals.
\begin{enumerate}
    \item If we want to analyze fMRI data over a population, we would first take image time-series.
    \item Then, we would normalise our data to align them with one another. Normalisation means we average the looks of the brain across all individuals, and then try to match individual brains to fit the template of the average normalized brain. We use a computer algorithm to do this.
    \item Then, we would smooth them. 
    \item We run a regression model to predict. Most commonly, a general linear model is used. We then correct it and then statistically analyze our data.
\end{enumerate}
\subsection{Independent variables can include task events or predictions of behavioral models}
\subsection{IVs can also be time series from other brain regions in the same or different participants}
You can take the time series from one region and correlate it with other regions. For example: if you want to see what happens to the regions outside of the hippocampus when the hippocampus is active, you can take the time series from the hippocampus and use it as an independent variable to regress against all of the other regions in the brain. You can conduct experiments across individuals as well.
\subsection{Multi-voxel pattern analysis-an alternative and increasingly popular way to analyze fMRI data}
Brain regions and neurons don't respond to stimuli in isolation. They are very interconnected. We can use this distributive code to get a more accurate signal of whatever the subjects are trying to do.
\begin{itemize}
    \item The basic idea is to explain, distinguish, or predict behavior as a function of distributed brain activity patterns.
    \item The extent of this distribution could be a fairly local area of few millimeters, the entire brain, or anything in between.
    \item The patterns can serve as input to regression models or machine learning algorithms.
\end{itemize}
\subsection{Multi-voxel pattern analysis- a summary}
The idea is to take two or more voxels and try to use those to explain how different stimuli or task conditions may differ between them. These voxels can be neighbouring voxels or completely distant/irrelevant voxels.
\subsection{Types of MVPA}
\begin{itemize}
    \item Classified-based MVPA: Activity in voxel 1 and activity in voxel two are graphed on x and y axis. Once you realize that the data is in clusters, you can put a line in between and discern which cluster is, for example, a face and which one is a scene.
    \item Similarity-based MVPA: Rating the representations and quantifying the similarity between them.
\end{itemize}
\subsection{How can we use fMRI in Neuroeconomics}
\begin{itemize}
    \item Plassman, O'Doherty, and Rangel (2007)
    \item Research Question: What brain areas reflect the stimulus value in simple choices between primary rewards (e.g. foods)?
    
\end{itemize}

\subsection{Plassman et al., Experimental Design}
Participants would not eat for four hours before the experiment.
\begin{itemize}
    \item Two experimental groups: 50 free trials vs 50 forced trials
    \item Free trials: you would see the picture of a food item (butterfinger candy bar) with a question mark below the image. Question mark means that they would be able to bid for this item freely. After this, there would be a short bid to contemplate how much they would pay for this food.
    \item Afterwords, there is the bidding, and the feedback round.
    \item Forced condition: no question mark, there is a number, they have to bid that much.
\end{itemize}
Once they are done with the scanner, the participants leave the scanner and hang around the lab for thirty minutes more. If their bids were the winning bid, they got to eat the item, if not, they remained hungry for thirty more minutes. 
\subsection{Using BDM auctions to measure stimulus values}
\begin{itemize}
    \item Critical to have a real-time and incentive compatible measure of stimulus values
    \item Becker-DeGroot-Marshack auctions widely used in economics for this purpose
    \item BDM auction rules
    \begin{itemize}
        \item random price (p) drawn from urn
        \item if bid $\geq$ p, get food item and pay p dollars
        \item if bid $<$ p don't get food and pay 0
    \end{itemize}
    \item Think of the bid as a monetized measure of the stimulus value
\end{itemize}


\subsection{Relevant features of the experiment}
\begin{itemize}
    \item Free vs Forced trials: the brain may automatically react to pictures of food you typically like or dislike that may not be related to the computation. This way, by adding the forced condition, you can subtract the activity that is not helping with the computation of the bid.
\end{itemize}
\subsection{BOLD signal magnitude is greater in Free vs Forced}
More activity in the ventromedial prefrontal cortex or orbitofrontal cortex (OFC). More lateral regions and the middle regions are more strongly lit in the free condition than the forced. Peak response at 5 seconds due to the fMRI delay. THIS RESULT IS THE AVERAGE ACTIVITY

\subsection{Is there a representation of the stimulus value on each trial}
They want a trial-by-trial variation on the willingness to pay for the food item.
They wanted to see if the trial number and stimulus value correlated with the activity of any individual part of the brain.

\subsection{vmPFC and dlPFC encode for WTP in free trials, but not in forced trials}
vmPFC and dlPFC reflect stimulus values during decision making situations. They are correlated with actively making a situation instead of just taking a given price for a food item. 

\subsection{Positron Emission Tomography (PET) Imaging Overview}
Unlike fMRI, we need to inject something (radiotracer) into the bloodstream of the participant.
\begin{itemize}
    \item Synthesize radiotracer
    \item Inject radiotracer
    \item Measure gamma-ray emissions from isotope (20-60 min)
    \item Reconstruct images of radiotracer distribution
\end{itemize}
\subsection{What can PET do that MRI can't?}
\begin{itemize}
    \item PET can measure the location and relative levels of specific molecules in the brain.
    \item These molecules can be anything labeled with a radioligand (something that
undergoes beta decay)
\end{itemize}
Since we synthesize the radiotracers, we can make them to specifically bind to certain regions and analyze where they aggregate.

\subsection{PET limitations}
\begin{itemize}
    \item Requires radioligand injection
    \item Relatively poor spatial resolution (1 to 5 mm)
    \item Expensive
    \item Similar temporal resolution to fMRI for functional analysis 
    \begin{itemize}
        \item Still relying on blood flow
    \end{itemize}
\end{itemize}

\subsection{Are there any neuroscience techniques with good temporal resolution}
\begin{itemize}
    \item yes
    \begin{itemize}
        \item EEG
        \item MEG
        \item Electrophysiological recordings
    \end{itemize}
\end{itemize}

\subsection{Electroencephalography (EEG)}
You have someone sitting on a chair in a dark room with sensors on the head and a screen in front of the participant. Voltages of the sensors might change. The number of sensors on the scalp would change as well.
\\Preferably, the subjects wouldn't blink (which is why the room is darker) so that there wouldn't be eye-blinking artifcats (which are significant, since the blinks have high amplitude).

\subsection{EEG}
\begin{itemize}
    \item Very old, first used in humans by Hans Berger (1924)
    \item A tracing of voltage fluctuations versus time recroded from electrodes placed over scalp in a specific array
    \item Represents fluctuating dendritic potentials in superficial cortical layers
\end{itemize}
EEG is limited to neurons arranged in a certain orientation. 
With EEG, we get a time-series of voltage change
\subsection{Event-related potentials (ERP)}
\begin{itemize}
    \item It is common to viualize/analyze the EEG siggnals time-locked to specific task events (decisions)
    \item These time-locked patterns are known as event related potentials
    \item Averaging ERPs improves signal to noise
    \item Can compare responses to specific events at a given latency
\end{itemize}
Essentially, if you are time-locked to a specific event, when you average them, you get a representative average on how the evoked signals may look like, whereas the noise, once it gets averaged, gets reduced, which allows for a comparison of signals.
\subsection{Where do EEG signals or ERPs Come From}
Excitatory neurotransmitter released on apical dendrites causes positive charges to flow into dendrites -small electrical currents
\\Any neuron on its own would be very hard to measure, however, luckily in the cortex, lots of neurons are lined up in the same orientation. Thus, we can sum the signals in the neurons of the same orientation. 
\\To be recorded at a distance, large numbers of neurons must have similar voltage fields (ie be pointed in the same direction).
\\We measure the sum of currents from an equivalent dipole
\subsection{Where Do ERPs Come From}
Scalp-recorded potentials are possible only for layered structures with consistent orientations. Primarily, this happens in the cerebral cortex.
\\Open Field:= The neurons are organized similarly with very similar orientations (the outer parts of the brain)
\\Closed Field:= The neurons are organized chaotically, mostly the inner parts of the brain, such as the striatum. We can't aggregate the signals in these neurons because the signals would cancel out.

\\We can easily tell when a signal arrives in the sensor array, but its harder to say exactly where it is coming from

\begin{itemize}
    \item Voltages spread through the brain by "volume conduction"
    \item Nearly speed of light
    \item Voltage everywhere except at postive-negative transition
    \item Skull causes lateral spread (like spraying a hose on cardboard). The skull blurs the signal a bit, making it even harder to know where the signal came from.
\end{itemize}

\subsection{Magnetoencephalopgraphy (MEG)
}
There is always a magnetic field perpendicular to an electric field.
\begin{itemize}
    \item Magnetic fields travel around electrical dipoles
    \item The skull is transparent to magnetism -- less blurring compared to EEG
    \item easier to localize signals compared to EEG, but still very a difficult problem
\end{itemize}
\subsection{The Superposition Problem}
Limits the ability to determine where the signal comes from
\subsection{What types of Neuroeconomics questions can EEG or MEG address?}
Page 57 of Lecture 4 slides.
\\Come to the lab hungry. An initial BDM Bidding. Then, the EEG scanning round. We are going to rate if you would actually eat this food item. 3 preference rounds of 15 minutes. BDM Outcome part, wait for 10 minutes.

\subsection{ERP evidence of stimulus value timing}
We can see how the brain signals evolved in certain brain regions. 
\\In the study on page 58, the preferences start to differ very early on in visual cortices. 400 to 550 ms shows that there is a difference in signals in the frontal areas of the brain. Even greater separation between the different levels of stimuli.
\\Positive and negative deflections in the EEG don't depend on activity, they depend on orientation.
\\Estimated cortical sources for ERP signals on slide 58.

\subsection{Must there always be a trade off between spatial and temporal resolution}
Yes and no
\begin{itemize}
    \item Electrophysiological recordings have very precise spatial and temporal resolution
    \item Unfortunately, these techniques are also very invasive.
\end{itemize}
\subsection{Single unit recording of amygdala neurons during food decisions}
Electrophysiological study of human patients do exist (Jenison et al., 2011).
Neurons in amygdala encode stimulus value with increasing and decreasing firing rates. 
\\Some neurons increase firing when the amount of money they are going to pay increases. Some neurons decrease firing when the amount of money they are going to pay increases. Positive and negative slopes in this study does show increasing and decreasing firing rates. 
\subsection{Electrophysiological Recording}
\begin{itemize}
    \item Similar recordingsg can be made in animal models
    \item However, there are limits to what types of behaviors animals can be trained to do.
\end{itemize}
It is a bit more difficult, since animals aren't as intelligent as humans, so you have to train them in a certain way so that they understand the task like we do. For example, you cannot ask a rat how much they would pay for a chocolate bar so you need to measure desire in a different way and you need to train the animals a certain way as well.

\section{Lecture 5: Shortcuts and Biases in Decision-Making}
\subsection{Main points in this lecture}
Human decision makers have limited cognitive resources and often use heuristic strategies to reduce computation effort and speed choices
\\Evidence for/against different reasons for decision biases from behavioral and brain data
\subsection{Decision strategies and heuristics}
There are numerous strategies for selecting an option in choices over complex goods.
\begin{itemize}
    \item Most rational choice models assume that choosers acquire as much information as possible in order to make the best choice.
    \item This strategy is exemplified by the weighted action method
    \item One other version of the strategy: add attribute values regardless of importance
    \item Lexicographic strategy: take the item with the highest value on the most important item.
    \item Elimination by aspects: eliminate items from choice set that don't meet criterion on an attribute in order of importance.
    \item Satisficing: Consider items sequential in order of choice set and choose as soon as one is good enough.

\end{itemize}

\subsection{Do people satisfice}
Humans especially satisfice in time constraints.

\subsection{The best option was selected less often in more complex situations}
The probability of finding the best option decreased with increasing complexity and the number of options.

\subsection{What is the level of good enough?}
Tracking clicks in the Caplin, Dean, Martin (2011) study. 
\\There does seem to be a level of good enough but it also depends on the total number of options.
\\It also depends on the work that needs to go into evaluating those options.
\\There is both a trade-off between the outcome/rewards of a search and the complexity of the search.
\subsection{The efficiency of a heuristic depends on the choice conditions}
Environments also factor into picking the most efficient heuristic. Slide 15, Lecture 5
\\The difference between the two environments is that there is a higher correlation between attributes in B than A. This means an option high in attribute 1 will be higher in attributes 2-n so lexicographic becomes fast and accurate.

\subsection{The efficiency of a heuristic depends on the choice conditions}
There is empirical evidence that people readily adapt their choice strategies to contexts and time constraints.
\subsection{Interim Summary
of the lecture until now}
\begin{itemize}
    \item Heuristics CAN facilitate quick and reasonably accurate decisions, but the accuracy of heuristics depends on the decision context.
    \item People will use simplifying heuristics and shortcuts to avoid the effort involved in complex cognitive tasks.
    \begin{itemize}
        \item Naturally, preferences over mental effort vary across individuals.
    \end{itemize}
\end{itemize}
\subsection{Framing effects as an example of bias}
\begin{itemize}
    \item Choices are susceptible to the manner in which options are presented
    \begin{itemize}
        \item Violates axioms of rationality
    \end{itemize}
    \item Framing effects are frequently attributed to emotional influences (eg fear of losses) and thought to be the result of dual-process (System 1 vs System 2) conflicts
    \begin{itemize}
        \item Question to ask: Is there good evidence for this?
    \end{itemize}
    \item Framing effects can be attenuated by enchancing engagement or elaboration on the decision problem.
\end{itemize}
\subsection{How does the framing effect relate to limited resources or resource allocation?}
\begin{itemize}
    \item Framing effects are sensitive to the level of processing and the population studied
    \begin{itemize}
        \item More elaboration over the decision reduces or eliminates framing effects
        \item There are studies showing that experts don't show framing effects in their field of expertise
    \end{itemize}
\end{itemize}
\subsection{Elaboration and Framing effects}
Kahneman and Tversky (1981) and Takemura (1994) show that high elaboration changes choices.
\subsection{Are framing effects caused by an emotional reaction to salient loss?}
A popular explanation for the framing effect relies on competition between deliberate, rational thought and emotional reactivity. Often this competition is incorporated into a dual-process framework.
\subsection{Neural evidence for Emotion vs Engagement in the context of Framing effects}
\begin{itemize}
    \item Initial fMRI studies did find that
    \begin{enumerate}
        \item Bbrain regions associated with emotional processing, specifically the amygdalae, were more active when people decided in accordance with, versus against, typical framing effects
        \item Brain regions associated with cognitive control and regulation were more active when people decided against compared to along with typical framing effects
    \end{enumerate}
    \item This was interpreted as evidence in favour dual-process models that assumed competition between emotional and rational, deliberative brain systems.
    \item BUT more recent work calls the completeness of this conclusion into question
\end{itemize}
\subsection{Patients with complete bilateral amygdala lesions show framing effects}
Talmi et al., 2010 Neuropsychologia
\begin{itemize}
    \item Remember that a popular hypothesis is that the framing effect results from emotional signals generated by the amygdalae
    \begin{itemize}
        \item If this is true, then individuals without these brain structures should show reduced or no framing effects/
        \item This is not the case, as we have just seen.
    \end{itemize}
    \item There are multiple reasons why these patients might show framing effects despite not having amygdalae, but these results certainly call into question amygdala-mediated emotional processing as the core cause of the framing effect.
\end{itemize}
\subsection{Reason's Enemy is not emotion: engagement of cognitive control networks explains biases in gain/loss framing}
\begin{itemize}
    \item Li and colleagues attempted to provide new insights into framing effects by explaining brain-wide patterns of activity instead of single brain regions one at a time.
    \item Li et al use an automated meta analytic tool (neurosynth) that is continously growing in terms of its scope and research utility.
    \begin{itemize}
        \item The backbone of Neurosynth is the automated meta-analysis of fMRI results and topics from published papers.
        \item At the time Li et al did their work, neurosynth allowed them to compare their results fmo 143 participants to meta-analytic data compiled from over 8000 other studies.
    \end{itemize}
\end{itemize}

\subsection{Neurosynth}
Automatically scrapes html versions of published papers to create associations between terms occuring in the text of a paper and reports of activity at specific coordinates
\\Generates a very large database of term vs activity maps
\\The automaticity of this process results in some inaccuracies. For example, terms used frequently in a paper may not be what the paper is about or regions showing greater or less activity are treated the same.

\subsection{Participants do show the framing effect and the size of this effect varies across people}
\subsection{Using whole-brain patterns of activity to try and understand framing effects}
\begin{enumerate}
    \item Step 1: Compute the group-level patterns of brain activity for frame-consistent versus frame-inconsistent choices in the sample of 143 participants.
    \item Step 2: Run correlations between this whole-brain map and each of the 2592 term-based, z-statistics maps from an association test from Neurosynth.
\end{enumerate}

\subsection{Historgram of correlations between the Framing effect pattern and meta-analytic maps of different terms}
Slide 36
\begin{itemize}
    \item Neural profiles for emotion (NPe) are not the ones most strongly correlated with the differences in activity between frame-consistent and inconsisntent choices.
    \item Instead, we see that
    \begin{itemize}
        \item NPs for terms related to resting state or default-mode activity are most positively correlated with the framing effect contrast
        \item NPs for terms relating to task engagement and executive function or cognitive control are most negatively correlated with the framing effect contrast
    \end{itemize}
\end{itemize}
\subsection{Computing the degree of explained variance for emotional NPs versus task (dis)engagement NPs}
NoE, key idea is that they compute partial correlations
\\Partial correlations with NPe controlling for NP+/- and partial correlations with NP+/- controlling for NPe

\subsection{NPs explain relatively little of the shared variance between the framing contrast and NP+/-}
\subsection{Explaining individual trial outcomes}
Procedure: Compute neural similarity between NP+, NP- and NPe on each trial. Then run a logistic regression using these 3 variables plus response time to explain choice outcomes.
\\Result: NP+ and RT are significant, others are not.
\subsection{Relation to previous fMRI findings in amygdala}
Note that when examining regions one by one, Li et al replicate findings from previous findings in the amygdala
\\However, interpreting these results in the broader context of whole brain activity leads to more nuanced conclusions.
\subsection{Conclusions from Li 2017}
These results don't rule out emotions as a reason for framing effects
\\They do indicate that emotions are not the sole, or perhaps the primary driver of framing effects.
\subsection{Relating this brain-wide pattern analysis to behavioral experiments on elaboration levels and choice
}
Increasing elaboration during decision making results in diminished framing effects
\\Making choices that are inconsistent with framing effects is associated with brain activity patterns that are typical for engaged, controlled processing.
\begin{itemize}
    \item On the other hand, choosing in line with framing effects is assocaited with brain activity patterns typically seen during "resting state" paradigms
    \begin{itemize}
        \item During resting state paradigms subjects are asked to lay quitely in the scanner and do nothing for 5-1o minutes (shouldn't sleep)
        \item What we observe during these paradigms has been described as mind-wandering, default mode or Random Episodic Silent Thought
    \end{itemize}
\end{itemize}
\subsection{Summary until now}
\begin{itemize}
    \item Framing effects have been shown to exist across several domains.
    \item The size of the effect varies across individuals
    \item Neural and behavioral data suggest that emotion-based dual-process explanations for framing effects are incomplete
    \item Cognitive strategies such as elaboration can reduce the influence of frames and the relative level of engagement or effort put into choice may, at least partially, explain why framing effects exist.
\end{itemize}

\subsection{Attention and deviations from Expected Utility in decisions under risk}
\begin{itemize}
    \item Decision makers often deviate from eU
    \item Cumulative Prospect Theory (CPT) allows for deviations from linear probability weighting and loss aversion (Tversky & Kahneman 1992). 
\begin{itemize}
    \item Better describes human decisions
    \item Doesn’t directly explain why they show non-linear probability weighting or loss aversion though  
\end{itemize}

\end{itemize}
\subsection{How CPT parameters influence value and probability}
You can change the gamma and deltas to obtain different curves
\subsection{Decision screen for Experiment 1 in Pachur et al 2018}
You have two gambles with outcomes and probabilities. When you click a box, if you want to look at another box, you click on it but the previous box closes. The researchers measure how much time you spend looking at each box. When you're ready to make a decision and choose a gamble, you click on the buttons on the right.
\subsection{Attention indices}
\begin{itemize}
    \item Attention$_{O}$ = the median (across all gamble problems) of the time spent inspecting all outcome information
    \item Attention$_{P}$ = the median (across all gamble problems) of the time spent inspecting all probability information
    \item Attention$_{LA}$ = the median (across all gamble problems with mixed gambles) the ratio of time the participant spent inspecting loss outcomes 
    \begin{itemize}
        \item i.e., O$^{-}$/O$^{+}$
    \end{itemize}
\end{itemize}
\subsection{Attention is correlated with loss aversion, outcome sensitivity, and probability sensitivity}
\subsection{Attention is not related to the elevation parameter (delta)}
Attention is not altering your baseline preferences but it is shifting how you factor in your gains and losses.
\subsection{CPT parameters related to attention}
All the values in CPT is related to attention.

\subsection{Experiment 2, Does attention play a causal role?}
\begin{itemize}
    \item Three attention manipulation conditions:
    \begin{itemize}
        \item Loss attention (n = 40)
        \begin{itemize}
            \item Loss outcomes open for 900 ms
            \item All others 300 ms
        \end{itemize}
        \item Gain attention (n = 41)
        \begin{itemize}
            \item Gain outcomes open for 900 ms
            \item All others 300 ms
        \end{itemize}
        \item Control (n = 39)
        \begin{itemize}
            \item All boxes open for 300 ms
        \end{itemize}
    \end{itemize}
\end{itemize}

\subsection{The duration manipulation changed looking times and loss aversion}
\begin{itemize}
    \item Attention$_{LA}$
    \begin{itemize}
        \item Loss-attention group = 2.82
        \item Control group = 1
        \item Gain-attention group = 0.34
    \end{itemize}
\end{itemize}
\subsection{Conclusions from Pachur et al 2018}
\begin{itemize}
    \item Attention is correlated with deviations from EU
    \item Differences in attention to gains relative to losses can cause loss aversion
\end{itemize}
\subsection{Another form of bias -The Endowment Effect}
\begin{itemize}
    \item The Endowment effect refers to the phenomenon that people behave as if they place more value on an item simply because they own it
    \begin{itemize}
        \item Famous examples of trading/buying/selling mugs or pens given to participants in lab experiments
    \end{itemize}
    \item The size of this effect is debated, but the difference in buy/sell prices has been found to be consistently significant even when subjects are told about the endowment effect
\end{itemize}
\subsection{Market experience and the Endowment effect}
\begin{itemize}
    \item Engelmann and Holland (2010) designed a series of experiments to test the effect of market experience on the Endowment effect
    \item The key manipulation is a forced trading condition
\end{itemize}
\subsection{Experimental Design}
\begin{itemize}
    \item All participants endowed with one of two goods
\begin{itemize}
    \item Ex. A bag of coffee or rice, package of crisps, can of cola, pen, notepad
\end{itemize}
\item Trading sessions lasted 5 mins
\begin{itemize}
    \item Free conditions had no restrictions
\item In forced conditions, participants could not take home the same item that they were originally given (i.e., they were forced to trade). 
\item Asymmetric supply of one good was introduced in some sessions to prompt faster trading.
\item Following the trading sessions all participants were given the same good as compensation for participation in addition to what they could keep from the trading session.
\begin{itemize}
    \item Essentially the subjects are re-endowed with the good.
\end{itemize}
\item In the one-on-one debrief session with the experimenter, the participants were given the opportunity to trade that good for another.
\begin{itemize}
    \item This trading opportunity is the dependent measure in the following regression. This is the outcome of the experiment.

\end{itemize}
\end{itemize}

\end{itemize}
\subsection{Just as forced elaboration can reduce the Framing effect, market experience can blunt the Endowment effect.}
\subsection{Take home messages}
\begin{itemize}
    \item People generally adapt their strategy to match the context and reduce effort
\begin{itemize}
    \item They may not always do this in an optimal manner. 
\end{itemize}
\item It is unlikely that emotions are the sole cause of seemingly irrational behaviors.
\item There is also good evidence that experience and attention/elaboration reduce Framing effects, Endowment effects, and other seemingly irrational behaviors.
\end{itemize}

\section{Lecture 6: Valuation Systems in Goal-Directed Choice}
\subsection{What is goal-directed choice?}
\begin{itemize}
    \item Choices where values are assigned to stimuli/actions by computing action-outcome associations and then evaluating the rewards associated with each outcome
    \item Also known as "value-based" choice
\end{itemize}
\subsection{Stages of goal-directed choice}
\begin{enumerate}
    \item Representation: First, you perceive a question. What are the feasible actions? Internal states? External states?
    \item Valuation: What is the value of each action
    \item Action selection: Chose actions based on valuations
    \item Outcome evaluation: How desirable aer the outcomes and states that followed the action
    \item Learning: Update the representation, valuation, and action selecting processes
\end{enumerate}
\subsection{Other types of valuation systems}
\begin{itemize}
    \item Pavlovian: assigns values to a small set of behaviors that are evolutionariliy appropriate responses to particular environmental stimuli
    \begin{itemize}
        \item Salivation
        \item Freezing
        \item Approaching food
    \end{itemize}
    \item Can learn to associate unconditioned stimuli (US) with previously neutral stimuli (CS)
    \item Habitual: can learn, through repeated training, to assign values to a large number of actions
    \begin{itemize}
        \item Not limited in the same way as Pavlovian learning
    \end{itemize}
    \item Key characteristics of habitual valuation systems:
    \begin{enumerate}
        \item Learn to assign values to stimulus-response associations (which indicate the action that should be taken in a particular state of the world), on the basis of previous experience, through a process of trial-and-error
        \item Generally learn to assign a value to actions that is commensurate with the expected reward that these actions generate, using as sufficient practice is provided and the environment is sufficiently stable 
        \item In the habitual system, it would take a while to unlearn a habit. For example, you open the lights when you go into a dark room. Now, whenever you go in, assume that an electric grid shocks your feet. You would unlearn the habit of turning on the lights eventually, however, it would take some time. With goal-oriented learning, however, it would be way quicker to unlearn the habit.
    \item Because values are learned by trial-and-error, habit systems learn relatively slowly and can forecast the value of an actions incorrectly immediately after a change in the action-reward contingencies.
    \item Rely on 'generalization' when assigning action values in novel situations
    \end{enumerate}
   
\end{itemize}
\subsection{Learning the value of actions}
\begin{itemize}
    \item Both Pavlovian and habitual systems learn in a manner consistent with Temporal Difference (TD) models
    \item Goal-directed system can use this information too, but is not limited to it.
    \begin{itemize}
        \item It can learn by observation as well
    \end{itemize}
\end{itemize}

\subsection{Outline of questions today}
\begin{enumerate}
    \item Are there neural systems that reflect the value of stimuli/actions at the time of choice?
    \item Can the same system represent positive and negative values?
    \item Is there evidence for a system that uses a 'common currency' to represent different types of goods?
    \begin{itemize}
        \item An example for this is: how would you compare the utility you would receive from a new bike with a new laptop? Does your brain have a common currency to compute your preferences?
    \end{itemize}
\end{enumerate}

\subsection{Evidence for value encoding in single neurons}
Experimental setup:
Monkeys are in front of a screen. They will receive a juice reward for their answers.
\\This study is conducted by eye movements.
\\In the screens in front of the monkey, there are colored squares. Each color tells him the flavor. The number of squares 
shows the amount of juice it will receive.
\\Once the square in the center turns grey, the monkey needs to saccade its eyes towards the reward. Once the monkey selects the option, the juice is delivered, and then it will move to the next question.

\subsection{How is the stimulus value measured in non-human primates}
Determine the marginal substitution rate
\\The data shows that the monkey would take 4.1 drops of water to one drop of juice A

\subsection{Recording sites in non-human primates}
Data on following slides from: Orbitofrontal cortex. Related findings from: ACC, or LPFC
\subsection{Some OFC neurons encode stimulus values of particular stimuli (independent of location}
Some neurons fire for A, some neurons fire for B. 

\subsection{Some neurons encode the identity of the chosen item}
These neurons will signal what I chose, not how much reward it gives me. In panel f, we see a neuron that fires when B is chosen. It doesn't encode how good B was, it just encodes that B was chosen.

\subsection{Some OFC neurons encode the value of the chosen item regardless of identity}
Some neurons fire more with value of the item increasing, some fire less with increasing value.
They show concave or convex patterns.

\subsection{Notes}
\begin{itemize}
    \item There is a representation of stimulus-specific value at the level of single neurons in the brain
    \item Single neurons also encode choice variables such as chosen value, and stimulus identity
\end{itemize}

\subsection{Meta-analyses of subjective value at the time of choice}
vmPFC, striatum, and the dPCC seem to encode for the value of choices.

\subsection{Outline of questions today}
\begin{enumerate}
    \item Are there neural systems that reflect the value of stimuli/actions at the time of choice?
    \begin{itemize}
        \item yes
    \end{itemize}
    \item Can the same system represent positive and negative values?
    \item Is there evidence for a system that uses a 'common currency' to represent different types of goods?
    \begin{itemize}
        \item An example for this is: how would you compare the utility you would receive from a new bike with a new laptop? Does your brain have a common currency to compute your preferences?
    \end{itemize}
\end{enumerate}
\subsection{How are negative values encoded at the time of choice?}
\begin{itemize}
    \item Which brain areas encode for aversive goal values?
    \item Can the same areas encode for aversive and appetitive goal values?
    \begin{itemize}
        \item There are long-standing debates in neuroscience about whether there are separate systems for positive and negative values
    \end{itemize}
\end{itemize}
\subsection{Experimental Design}
Two conditions: one food is appetitive, one food is aversive (you would pay to avoid it).
If you don't win the auction, you eat the food, if you win, you don't eat the food for the aversive condition.
\subsection{Areas encoding for aversive goal values in free trials}
fMRI studies show that positive and negative do overlap at certain points in the brain.

\subsection{Outline of questions today}
\begin{enumerate}
    \item Are there neural systems that reflect the value of stimuli/actions at the time of choice?
    \begin{itemize}
        \item yes
    \end{itemize}
    \item Can the same system represent positive and negative values?
    \begin{itemize}
        \item yes
    \end{itemize}
    \item Are negative values always associated with less activity?
    \begin{itemize}
        \item No
    \end{itemize}
    \item Is there evidence for a system that uses a 'common currency' to represent different types of goods?
    \begin{itemize}
        \item An example for this is: how would you compare the utility you would receive from a new bike with a new laptop? Does your brain have a common currency to compute your preferences?
    \end{itemize}
\end{enumerate}
\subsection{Goal congruency signals in vmPFC}
Participants are making choices between different combinations of goods. Before going into the scanner, they will rate how much they would like to have these goods. In the scanner, they are asked to choose the good they want the most, and second, they are asked to choose the good they want the least.
\subsection{Goal congruency signals in vmPFC}
Negative things encoded as high activity when chosen the worst option and low activity when chosen the best option. The reverse is true for positive things. The firing isn't dependent on the value of the items but more so dependent on the value of the items with respect to our goal.
\subsection{Common Currency}
\begin{itemize}
    \item How/where does the brain represent different types of stimulus value?
    \item Can different reward types be compared in the same brain regions?
\end{itemize}
\subsection{Tests of common value representation}
\begin{itemize}
    \item Pre-scannnig: free response time, BDM auction. The person must choose between bookstore trinkes vs food.
    \item During scan: they try give you an item vs money and let you choose to see what encodes the value for different items.
\end{itemize}
The results show that there are differences between which region in the brain expresses these items; however, there are some overlaps as well.
\\vmPFC seems to correlate with the overlap and seems to activate commonly for all choices against a fixed monetary bid.

\subsection{Common Currency}
\begin{itemize}
    \item In both of the previous examples, we saw that some brain regions represent only one type of reward. In other words, there was not complete overlap between food, money, etc.
    \item This is important to remember, but id doesn't speak against the idea of a common currency representation.
    \item The common currency hypothesis only requires that the brain can represent various reward types on the same scale.
    \item A stronger test of the common currency hypothesis is if we can "read out" value from brain activity across different categories of goods.
    \item The following study uses a design similar in Chib et al, but adds a machine learning analysis to test if they can predict the value of goods across categories
    \item It will try to predict the value of one type of good, by being trained on another type of good.
    \end{itemize}

\subsection{Category-dependent and category-independent goal-value codes}
Can a classifier trained on activity from one category predict values in other categories?
\\The answer is yes, you can accurately predict across goods.
\subsection{Interim conclusion}
\begin{itemize}
    \item vmPFC can represent the value of many concrete rewards at the time of choice
    \begin{itemize}
        \item Juice/food
        \item Money
        \item Consumer goods
    \end{itemize}
    \item What about more abstract rewards? How do we compute values when the task is not about ourselves.
\end{itemize}
\subsection{Value computation in moral dilemmas}
Shenhav and Greene: Moral dilemma readings first similar to the trolley problem. You are on a rescue team heading to one direction to save a toppled boat. Then, you hear that another larger boat toppled at the opposite direction but there's a probability that a second rescue team can get to it. The probability varies by trial. What do you do? After reading the dilemma, trial 1 commences. Then ten more trials are conducted.
\\Here, the stimulus of expected value (EV) is computed as: Number of lives x probability of death. 
\subsection{Value computation in moral dilemmas}
The study showed that increasing moral expected value correlated with increasing activity in the vmPFC. Obviously, there are other regions that contribute to this as well, but the vmPFC seems to be the overlap/common  region.
\subsection{vmPFC represents the relevant value signal}
Another question is whether this valuation system is inherently linked to value for yourself.
\\They brought people into the lab, estimated their temporal discounting functions, and then paired them up with a person that has a temporal discount function that allows the experimenters to create a series of choices that are relatively distinct between the two people, but also with enough overlap where you would make the same choice so that the estimated value functions are relatively uncorrelated between the two of you. 
\\Every trial you get an instructor that you are either choosing for yourself or your partner.
\\Each trial has two options: Option A today or Option B at some random time.
\\If you are choosing for your self or your partner, you have to choose the best option.

\subsection{vmPFC represents the relevant value signal}
The "expected value" is the one relevant to the current choice.
\\We see from the results that in the vmPFC, the voxels shift from executed value to modelled value. Executed: the one that is relevant for the person who you're supposed to be choosing for on that trial. So if you're choosing for yourself it's you, if you're choosing for Mary, it's Mary. 
\\The modelled is the alternative choice on that trial.
\\You always compute executed and modelled values, but which one you compute where depends on the trials. The red portion on slide 47 show the choices you make for yourself. 
\\The value system isn't locked into your own values but it is about whoever is choosing.
\subsection{vmPFC represents the relevant value signal}
Self value is correlated with the vmPFC when it is choosing for self. When choosing for the other person, the other value is more relevant.
\begin{itemize}
    \item vmPFC reflects the values you would assign when choosing for yourself
    \item vmPFC reflects the values you have learned another would assign when choosing for him/her
    \item The values computed are those that are appropriate for the choice situation
    
\end{itemize}
\subsection{Notes}
\begin{itemize}
    \item vmPFC represents stimulus or subjective values across a wide range of reward types
    \item vmPFC is not the only region that represents stimulus value, but it is one of the most consistent regions to do so
\end{itemize}
\subsection{Is vmPFC necessary for goal-directed choice}
\begin{itemize}
    \item We have consistently seen vmPFC reflecting the value of stimuli/actions at the time of choice
    \item However, other areas (e.g. striatum appear to do so too)
    \item Also, all of the data shown so far are only correlational
\end{itemize}
\subsection{Testing the generalized axiom of revealed preference in patients with vmPFC damage}
Camille et al 2011, page 53, the image shows the damaged areas overlapped in the 9 patients of the study. There are 22 controls.
\\Large overlap of damage in the vmPFC region.
\begin{itemize}
    \item Remember, the basic notion embodied in GARP is that a person's choices should be internally consistent and transitive. For example,
    \begin{itemize}
        \item If someone picks X over Y, then they should not at another point select Y when X was also available.
    \end{itemize}
    \item This study presented brain damaged patients with choices for different bundles of chocolate bars and juice boxes.
    \item On average, control subjects had 1.41 GARP violations with a majority making no GARP violations.
    \item VMF patients had a mean of 4.89 GARP violations, with a large majority making two or more GARP violations. Small samlpes and high variability, so take it with a grain of salt still. 
    \item Variance in the behavioral effect may relate to variance in the lesion location or severity as well.
\end{itemize}

\subsection{Conclusion}
\begin{itemize}
    \item vmPFC lesion patients' choices violated GARP significantly more often than controls
    \item Suggests that vmPFC is necessary for optimal decision making
    \begin{itemize}
        \item Note that vmPFC lesion patients still make choices, they just don't compute or compare values as consistently
    \end{itemize}
\end{itemize}

\subsection{Can we use neural representations of value/goal relevance in economics}
\begin{itemize}
    \item Predicting micro-lending
    \item Efficient allocation of public goods
\end{itemize}
\subsection{Predicting Micro-lending}
Nora needs three thousand in micro loans to buy a truck to take her goods to the local market

\subsection{Initial internet study design}
\begin{itemize}
    \item Actual lending data provided by the micro-lending site Kiva
    \item Borrowers' text was assessed for valence using a standardized system
    \item Borrowers' photographs were rated for valence by people "hired" through Amazon Mechanical Turk
\end{itemize}
\subsection{Internet study results for funding rate (how quickly they reached the goal)}
If the photo creates positive arousal and the photo is identifiable, it facilitates reaching the goal. Repayment term is negatively correlated with rate of funding.
\subsection{Affective ratings predicted lending rates}
Photographs in the top decile of positive-arousal ratings were funded at 8.04 dollars more per hour than were photographs in the bottom decile; they achieved full funding in 11.5 percent less time
\subsection{Neuroimaging experimental design}
This gave an idea to the researchers. Affective responses in the brain might be useful in predicting rates of funding.
\\Experimental design: Replicating the online experiment in the fMRI scan.
\\Step-by-step:
\begin{enumerate}
    \item Show photograph
    \item Show loan page
    \item Subject makes a decision on whether to fund the loan or not
    \item After scanning, subjects made ratings about their affective responses to the pictures and text descriptions.
\end{enumerate}

\subsection{Neuroimaging study results}
Nucleus accumbens activity is correlated with aggregate lending rate. 
\subsection{Neuroimaging study results on predictions of actual lending rates on the Kiva site}

\subsection{Notes}
\begin{itemize}
    \item Affective ratings predict micro-lending rates better than actual choices
    \item Neural responses in the nucleus accumbens (a region linked to affective responses) can improve on predictions from affective ratings alone
    \item The increase in predictive power fom NAcc activity is significant, but rather modest.
\end{itemize}
Can predictions of value from brain activity contribbute more in other choice contexts?
\begin{itemize}
    \item Mechanism design for public goods creation
    \end{itemize}

\subsection{Public Goods}
\begin{itemize}
    \item Examples: National defense, environmental protection, local parks
    \item The utility dervied from such goods vary across individuals
    \item The benefits are non-excludable
    \begin{itemize}
        \item Ex: once a public park is created, everyone can go and enjoy it
    \end{itemize}
\end{itemize}
\subsection{The free-rider problem}
Because a public good is non-excludable, self-interested individuals have an incentive not to contribute to its creation, but still enjoy its benefits.
\subsection{Mechanism Design}
The goal of mechanism design is to create situations or institutions that make it advantageous for self-interested individuals to reveal their true values-and pay accordingly
\subsection{4 Desirable Mechanism Properties}
\begin{enumerate}
    \item Social efficiency
    \begin{itemize}
        \item requires that the optimal amount of the public good always be produced, meaning that the net benefit to the group is maximized.
        
    \end{itemize}
    \item dominant strategy incentive compatibility
    \begin{itemize}
        \item requires that the wealth-maximizing strategy for each member of the group is to reveal his or her true value, regardless of others' values or behavior.
        \item ensures that every subject has a financial to tell the truth regardless of this or her beliefs about the other group members.
    \end{itemize}
    \item balanced budget
    \begin{itemize}
        \item requires that the cost of the public good be completely covered by the members of the group
    \end{itemize}
    \item voluntary participation
    \begin{itemize}
        \item requires that the expected value from participating in the mechanism be nonnegative for each individual, so that members do not have to be coerced into participating
    \end{itemize}
\end{enumerate}
A central result in economic theory is that there is no set of rules satisfying all four desired criteria simultaneously.

\subsection{Neurally Informed Mechanism Design}
Work in neuroeconomics has shown the efficacy of a neurally informed mechanism in creating institutions with optimal social efficiency
\\The key aspects of the NIM are
\begin{enumerate}
    \item The ability o accurately read out participants values from brain activity
 
\item A set of taxes creating a dominant strategy to report your true value
\end{enumerate}
You report your values in the Krajbich study. There is a payoff/tax matrix. If the MRI says you have a low value for the good but you contradict it and say you have a high value, you get penalized. The MRI prediction and your own ideas must be  congruent to be paid.
\\Attention check occasionally so that you don't trick the system
\\The classifier used by Krajbich and colleagues had an accuracy of 0.6
\\Calibration study: how good is the classifier
\\Main experiment: Observed accuracy in main experiment
\\Guess: participant' guess of how accurate the classifier was.
\\The performance of the NIM is indistinguishable from the theoretical optimum and much better thant he best mechanism available based on choice alone.
\subsection{Notes/Conclusions}
\begin{itemize}
    \item Predicting an individual's value for a given good with fMRI measures of brain activity is possible
    \begin{itemize}
        \item accuracy is significant, but modest at this point
        \item even modest prediction rates can be combined with institutional mechanisms that result in better efficiency than is possible by observing choices alone
        \begin{itemize}
            \item This combination highlights the potential utility of combining brain-derived indicators of states or beliefs (high vs low value for a public good) with the tools of mechanism design or other more standard branches of economics.
        \end{itemize}
    \end{itemize}
    \item The studies by Krajbich et al and Genevsky et al are intriguing proofs of principle
    \item However, given the expense of neuroimaging and public opinion of "mind reading" you should not expect neurally informed mechanism designs to be implemented by governments any time soon.
\end{itemize}
\section{Attention}
\subsection{Premise: Values are constructed at the time of choice}
In economics, we don't know when the value is perceived or retrieved, but it is also not very important in those domains.
\\But in neuroeconomics, it becomes more relevant.
\begin{itemize}
    \item The brain has infinite resources
    \item Resource allocations during this construction process will influence valuation and comparison processes (decisions)
\end{itemize}
\subsection{The brain use efficient coding schemes}
\begin{itemize}
    \item Thebrain uses information about regularities in the environment to represent stimuli and states efficiently
    \item Although efficient codes are the optimal solution under resource constraints,
    they can cause biases and imprecision in  decision making
    \begin{itemize}
        \item eg Woodford, M (2020). Modeling imprecision in Perception, Valuation, and Choice.
    \end{itemize}
\end{itemize}
\subsection{Efficient codes and risky choice}
\begin{itemize}
    \item There are multiple forms of efficient coding used in the brain
    \item Codes that determine how we perceive numerical quantities depend on the distribution of quantities in the environment
    \begin{itemize}
        \item Perhaps surprisingly, this includes numbers written as words or shown as digits
    \end{itemize}
    \item Computation or representation is easier with numbers that are around us more. Different language speakers make different mistakes due to how much those numbers are prevalent in their native languages.
\end{itemize}
\subsection{Stimulus distributions influence the precision of efficient codes}
The optimal representation with a fixed output range is proportional to the CDF of the prior stimulus distribution
\begin{itemize}
    \item The exact relationship between  the CDF and the efficient code depends on quantity being maximized (accuracy, information, reward)
    \item The Frydman and Jin study discussed nex t use a uniform distribution so that the efficient code is identical for all 3 goals
\end{itemize}
\subsection{Testing resource-limited representation of numbers}
\begin{itemize}
    \item Task = decide if the number on the screen is above or below 65
    \begin{itemize}
        \item The low volatility context has a uniform distribution of 56-74
        \item The high volatility context has a uniform distribution from 31-99
    \end{itemize}
    \item Researchers will try to manipulate your previous probability distribution
    \item Assume we can distinguish only 19 magnitudes (this is an example, we don't know the true resource limit)
    \begin{itemize}
        \item This gives a precision of
        \begin{itemize}
            \item 1 for low volatility trials
            \item 3.6 for high volatility trials
               \item This means that we should have trouble judging whether a number is greater than or equal to 65 in the high volatility context than the low volatility context, if the idea of efficient coding impacts our idea representations
        \end{itemize}
     \item Performance is compared in the common range, 56-74
 \begin{itemize}
     \item Performance is compared in the common range, 56-74
 \end{itemize}
 \item Payoffs are calculated as 15 $\times$ accuracy - 10 $\times$ average seconds
\begin{itemize}
    \item Incentivize accuracy and speed to increase the effect of resource constraints. We want the subjects to do it quickly, as doing it slowly would allow the subjecs to easily compare the numbers.
\end{itemize}
    \end{itemize}
    
\end{itemize}
\subsection{Accuracy is lower in the high volatility condition}
The graph shows that, for numbers less than 65 especially, the low volatility condition performed better as their chance to classify numbers less than 65 as greater than 65 was lower.

\subsection{Response Times}
\begin{itemize}
    \item RTs increase near 65 for both conditions
    \begin{itemize}
        \item Behavior shows the ubiquitous discriminability or difficult effect
    \end{itemize}
    \item RTs are longer with high volatility
    \begin{itemize}
        \item suggests less precise representations
    \end{itemize}
\end{itemize}

\subsection{Risk lottery task}
How does efficient coding impact risk decisions.
Again two conditions: high volatility condition and low volatility condition.
\subsection{Predictions}
pX - C sigmoidal curve is steeper for the low volatility condition. This is a qualitative prediction.
\subsection{Results}
The data matches the prediction: the low volatility group had a lower chance of accepting the gamble when the yield was lower than the sure option, and a higher chance of accepting the yield, when it was higher than the sure option.
\subsection{Attention}
\begin{itemize}
    \item Attention is the process of flexibly controlling limited computational resources. Selective attention is good, as it allows us to focus on the aspects of our environment that our important and not take in irrelevant information. It can also impact the way we make decisions, if we are not focusing equally on all relevant information (giving the relevant information different weights).
\end{itemize}
\subsection{Attention and choice}
We have seen one example of how visual attention influences risky choices and loss aversion in a previous lecture.
\\Pachur study
\\Attention is correlated with loss averison, outcome sensitivity, and probability sensitivity
\subsection{Gaze bias both reflects and influences basic preferences
}
Shimojo: Which face is more attractive study. It found that as we get closer to making a decision, it is likelier for you to inspect the face you would be choosing.
\subsection{Attractiveness of abstract shapes}
Curve shapes are the same, more or less. 
\subsection{Gaze also reflects perceptual decisions}
Similar curves for this condition as well, except the "indicate disliked face" condition flattens out quicker and is less steep.

\subsection{Indicate the disliked face instead of more attractive}
The probability of looking at something compared to the probability of choosing it also depends on the way the question is framed. Indicate the disliked face is less steep and flattens quicker. The subjects looked at it less.
\subsection{Attention patterns when choices change}
When the same subjects were called back and asked the same question, the trend of looking longer continued, the closer the subjects were to deciding again, the likelier they were to look at the face they were going to choose. However, surprisingly, sometimes they diverged from their initial choice. One reason for this potential divergence is that they looked at the other picture longer this time. But, this is just a correlation.
\subsection{Casual manipulations of gaze}
New experiment. Two conditions: Longer and Shorter.
\\As you increase the amount of repetitions, percent preference for longer shown face increases.
\\The no gaze shift manipulations are inconsistent with a "mere exposure" effect.
\subsection{Visual attention and purchasing}
Three time periods: BDM bids, purchase choice, feedback
\\The results show that the more you look at an item, the likelier you are to buying it, the more you look at the price tag, the less likelier you are to buying it.
\subsection{Does attention amplify value or have a constant effect on choices?}
\begin{itemize}
    \item Many studies have shown that people are more likely to choose the item they fixated on longer
    \begin{itemize}
        \item There is debate about whether the influence of attention is additive or multiplicative
        \begin{itemize}
            \item Multiplicative: $\theta \times$ attended item value - (1 - $\theta$) $\times$ unattended item value
            \item Additive: $\theta$ + attended item value - unattended item value
        \end{itemize}
    \end{itemize}
\end{itemize}

\subsection{Predictions for decision time from each model}
\begin{itemize}
    \item Decision times are faster when options are more distinct.
    \begin{itemize}
        \item For perceptual judgements, this means more perceptually different
        \begin{itemize}
            \item Clearly bigger or smaller for example
        \end{itemize}
        \item For value-based choices this means more different in value
    \end{itemize}
    \item A multiplicative effect would amplify differences between sets of high valued options
\end{itemize}

\subsection{Multiplicative vs Additive influence}
Multiplicative: as the value increases, the response time would go down. 
\\Additive: as the value increases, the response time would be stagnant overall but the individual responses give a U shaped curve.
\subsection{6 datasets all show a negative correlation with a multiplicative effect}
Attention would multiply the values of the attended option vs the unattended option and make response times faster.
\subsection{Attention effects may vary as a decision unfolds}
Recent studies have indicated that, the multiplicative and additive effects may depend on which portion of the decision we are in. We might be shifting from an initial multiplicative effect towards an additive effect.
\begin{itemize}
    \item Westbrook et al examined the effects of a common dopamine agonist drugs on the willingness to engage in cognitive effort. In this study, they measured effort with a working memory task. They increased the difficulty of the working memory task.
    \begin{itemize}
        \item selective dopamine D2 receptor antagonist. This leaves more dopamine in the synapses.

    \end{itemize}
    \item Found that baseline dopamine levels in the brain were correlated with willingness to engage in cognitive effort
    \item Methylphehnidate increased willingness to complete a harder version of a memory  task
    \item Results show that, as difficulty increases, both antagonist and no antagonist group decrease in willingness to complete the task, but the antagonist group's willingness decreases slower compared to the non-antagonist group. This is correlated with the amount of dopamine in the striatum.
\end{itemize}

\subsection{Differences in dopamine correspond to fixation  problems}
Westbrook 2020 did a gaze study, where participants had to either do a harder task or an easier task, with the easier task paying less consistently. Both conditions hahd the level of difficulties described on the screen as well. However, the extent of the compensation differences between the two tasks varied from trial to trial. The study concluded that, the more you looked at the costs ( level of difficulty) of the hard task, the likelier you were to select it. They realized that, the more you looked at the benefits of the hard task (the monetary compensation), you were also more likelier to select it, however, the graph increases more steeply than the costs graph.
\\For people who choose the hard task, people look at and compare the benefits and compensations more and focus more on the hard task benefits. This effect is amplified for people who received dopamine antagonists.
\begin{itemize}
    \item Attention has a multiplicative effect until the bifurcation point
    \begin{itemize}
        \item Decision made, but not executed yet
    \end{itemize}
    \item Attention has an additive effect after the bifurcation point.
    \item This means that, early on, attention has a stronger impact on the value as it multiplies the value, however, as the subject is reaching the decision, after the bifurcation point, you have an additive effect, it will just determine where you will attend.
    \item This is why, in choices where you have a long delay between you choose and then implement, you would be more likely to see an additive effect: whereas, where the choice time is free, you might see a more multiplicative effect.
    \item Significant multiplicative effect before bifurcation and significant additive effect after bifurcation.
\end{itemize}
\subsection{Multiplicative vs additive influence of attention}
\begin{itemize}
    \item The debate is not fully resolves
    \item Thhere do seem to be multiplicative effects
    \begin{itemize}
        \item They may be limited to early in the decision phase
    \end{itemize}
    \item Additive effects may kick in later once an option is (nearly) selected
\end{itemize}

\subsection{It's not just about the quantity of attention an option receives}
\begin{itemize}
    \item We have seen examples of how looking longer influences choices
    \item The order of information acquisition also influences choices
\end{itemize}
\subsection{Information acquisition changes temporal discounting}
We are going to look at how people evaluate the magnitude and delays of the options available and how this relates to the probability of the option chosen.
\\Reeck et al 2018. In the experiment, participants must click each box with the mouse to see the information. Each will give you an amount of money and a delay and you have the right to choose how much you're earning and how much you will wait for it.

\subsection{Search strategies}
There are two types of strategies that people use to decide: Comparative and Integrative.
\begin{itemize}
    \item Comparative: This means that you are comparing the two attributes of the decision. This means that you are comparing the amounts to amounts and the delay to the delay. This means that you click on the amounts first and then the delays.
    \item Integrative: This means that you integrate the response first, and then compare. This means that you would first click on the amount of a choice and then check its respective delay and then do the same thing with the other option.
\end{itemize}
\subsection{Comparative searchers are more patient}
They are more tolerant of delays
\subsection{Experiment 2: Manipulating search to test causality}
This was done to see if the strategy affected the decision or if comparative searchers are naturally more patient.
\begin{itemize}
    \item Introduce a 1 second delay for discouraged searches
    \item Easy comparative condition
    \begin{itemize}
        \item Comparative transitions are immediate
        \item Integrative transitions incur a 1 sec delay
    \end{itemize}
    \item Vice versa for easy integrative condition
\end{itemize}
\subsection{Results for all trials}
\begin{itemize}
    \item Easy Comparative show more patience than Easy Integrative
\end{itemize}
\subsection{Results for trials in which search matched the intended manipulation}
\item Recover the framing effect in comparative searchers
\item Results are even stronger
\subsection{The association between search and patience is task dependent}
\begin{itemize}
    \item Choose between pairs of outcomes
    \begin{itemize}
        \item One sooner
        \item One later
        
    \end{itemize}
    \item Text is only visible if you look in a dotted rectangle
    \begin{itemize}
        \item Analogous to the mouse-tracking studies
    \end{itemize}

\end{itemize}
This is an eye-tracking study. If you look at one rectangle, the one you look at opens up but the other disappears.
\subsection{Payne Index}
\begin{itemize}
    \item PI := \frac{Alternative - Attribute}{Alternative + Attribute}
    \item Definitions: alternatives are the two alternatives in an option, attributes are option A and option B
    \item Higher PI means that you do more integrative search
    
\end{itemize}
Findings:
\begin{itemize}
    \item In contrast to the design in Reeck et al, now participants need to integrate sooner and later payoffs to compute the total amount of money
\item Does this change the relationship between search patterns and patience?
\end{itemize}

\subsection{In this context, integrative search is associated with more patience}
In this study, the average patient choices are positively correlated with the Payne Index.
\\Also, the implied discount functions for the comparators are more steep than the integrators.
\subsection{Integrators' choices are more sensitive to total reward.}
Thus the differences between are more complex and context dependent than what we can think
\subsection{Summarizing both studies}
\begin{itemize}
    \item Reeck show that information search patterns change temporal discounting
    \item Khaw show that the information search patterns relate to temporal discounting depends on the choice context
\end{itemize}

\section{Response times contain useful information}
 \subsection{Outline}
 \begin{itemize}
     \item Response times (RTs) inform researchers about decision makers' subjective values
     \item RTs inform experiment participants about one anothers' private information
     \item Combining RTs and choices in a structured model improves preferences estimates
     \item RT patterns predicted by sequential sampling models are seen in the field
 \end{itemize}
 \subsection{Choice RTs are proportional to discriminability}
 \begin{itemize}
     \item Thhe field of psychophysics has show that response times are proportional to discriminability (difficulty) in perceptual judgements
     \begin{itemize}
         \item Replicated many, many times
     \end{itemize}
     \item If economic decisions are based on differences in utility, then RTs should reveal the strength of preferences, not just preference orders
 \end{itemize}
 \subsection{RTs should reveal strength of preference, in theory}
 \begin{itemize}
     \item Suppose we ask two people, Anne and Bob:
     \begin{itemize}
         \item "Would you rather have 25 dollars today, or 40 dollars in two weeks?"
         \item Both say 40 dollars in two weeks
     \end{itemize}
     \item These choice outcomes don't tell us who is more patient in general
     \item Now suppose: 
     \begin{itemize}
         \item Anne made her choice in 5 seconds
         \item Bob made his choice in 10 seconds
     \end{itemize}
     \item Who is more patient?
     \item A faster choice should indicate a stronger preference, hence we can infer that Anne is more patient than Bob. 
 \end{itemize}

 \subsection{Decision times are proportional to value differences}
 Monotonic relationship between the response time and the preference.
 \subsection{Sequential sampling models of decision making}
 Drift diffusion model on page 7.
\\The line at the top and the bottom are the threshold. These are the levels of evidence required to make the decision. The more you make these thresholds larger, the longer it would take you to make a decision, but the less errors you would make while doing so as well. In other words, the longer you gather data, the less susceptible to noise your data will be and the higher the signal/noise ratio you will have and the lesser the errors you will make.
\\The rate at which the lines move towards the thresholds depend on the preferences of the chooser. The more someone likes an option compared to another, the faster the lines will go to the threshold.
\\Paper by Clithero 2018
\subsection{Sequential sampling models of decision making}
\begin{itemize}
    \item Sequential sampling models can have different stopping rules (thresholds)
    \begin{itemize}
        \item Constant over time
        \item Decreasing over time
        \item Based on a cost/benefit calculation for future sampling
        \item etc
    \end{itemize}
\end{itemize}

\subsection{Why do decision makers take multiple samples of value/utility}
\subsection{Example, two cheeses}
You don't have an inherent table immediately on your mind. You will have to think about your preferences. You will have distributions for the variables.
\begin{itemize}
    \item You can opt to take a single sample from distributions and compare their values. This is susceptible to incorrect decision making.
    \item By taking more and more samples, we are more likely to make the correct decisions but it also costs more time.
\end{itemize}
\subsection{Do RTs contain useful information in practice}
\begin{itemize}
    \item If choices are based on a sequential evidence accumulation process, then RTs should be proportional to value differences.
    \begin{itemize}
        \item Other things influence RTs too
        \begin{itemize}
            \item Age, health
            \item Choice complexity
            \item Attention/distraction
            \item Etc
        \end{itemize}
    \end{itemize}
    \item Is the relationship between strength of preference and RT strong enough to be useful?
\end{itemize}
\subsection{RTs do reveal strength of preference in lab experiments}
Take three domains for the experiment: Risky, intertemporal, social. Can we use the response times in these three domains to infer something about the underlying strengths of preference.
\begin{itemize}
    \item In each choice domain, the authors capture choice-derived preferences with the following models.
    \item Note that they take arguably reasonable steps to simplify the models or experiments such that risk, intertemporal, and social preferences are captured by a single parameter.
\end{itemize}

\subsection{Risky choices were modeled with standard prospect theory}

\subsection{Intertemporal choices were modeled with a hyperbolic discount function}
\[U(x, d) = \frac{x}{1 + kD}\]
where x is the delayed monetary amount, k is the discount factor (higher is more impatient) and D is the delay period
\subsection{Social choices were modeled with Fehr-Schmidt}
\[U_{i}(x_{i}, x_{j}) = x_{i} -\alpha \times max(x_{j} - x_{i}, 0) - \beta \times max (x_{i} - x_{j}, 0)\]
where x$_{i}$ is he dictator's payoff, x$_{j}$ is the receiver's payoff, $\alpha$ reflects disadvantageous inequality aversion, and $\beta$ reflects advantageous inequality aversion. Each trial was designed to either measure $\alpha$ or $\beta$, so we treated this experiment as two separate datasets. 
\\In the choice sets we have, we either have disadvantageous or advantageous decisions but not mixed sets.
\subsection{Establishing a negative correlation between strength-of-preference and RT.}
In the subsequent graphs "indifference X"
\\We are going to plot RT on the Y axis.
\\The lower the strength of preference, the higher the RTs.
\subsection{One trial preference rankings}
\begin{itemize}
    \item Participants choose between
    \begin{itemize}
        \item A 50/50 lottery with a gain of 12 dollars and a loss of 7.5 dollars or
        \item 0 dollars for sure
    \end{itemize}
    \item A loss aversion coefficient of $\lambda$ = 1.6 would make someone indifferent in this case (assuming risk neutrality)
    \item This one choice outcome only tells us if $\lambda$ $\geq$ 1.6 or $\lambda$ $<$ 
    \begin{itemize}
        \item We can only form two groups of people
    \end{itemize}
    \item With RTs we can rank subjects that accept or reject the gamble
    \item Hypothesis: subjects with loss aversion closer to 1.6 have longer RTs
    \item We divide people into two groups: Risky option chosen vs Safe option chosen
    \item Graph made from $\lambda$ estimated from choices on x axis and RTs on y axis
\end{itemize}
\subsection{Uninformative choices}
\begin{itemize}
    \item RT-based inference could also be used when an experiment is flawed in such a way that most subjects give the same answer to the questions.
    \item Konovalov and Krajbich mimic this situation
    \begin{itemize}
        \item Use 4-10 trials from each data set in which most people gave the same response
        \item Only use participants that gave the modal responses
        \item Use RTs on 1-N trials to estimate strength of preferences
    \end{itemize}
\end{itemize}
\subsection{RTs from uninformative choices correlate with preferences estimated from all choices}
\subsection{Beyond ranks to parameter estimates}
Can you use RTs to estimate a parameter value such as the loss aversion coefficient or the discount rate
\begin{itemize}
    \item Konovalov and Krajbich propose a method to use RTs alone to estimate parameter values
    \begin{enumerate}
    \item identify trials with RTs in the upper 10$\%$ (the slowest decile)
        \begin{itemize}
        \item These should be trials where participants are close to indifference
    \end{itemize}
    \item Calculate the value of the preference parameter that would make the subject indifference between the two alternatives on each trial
    \item parameter estimate = average of the values from step 2
    
    \end{enumerate}
 \item Note that this gives a bounded estimate
 \begin{itemize}
     \item Upper (lower) bound: mean of highest (lowest) 10$\%$ of all possible indifference values
 \end{itemize}
\end{itemize}
\subsection{Preference parameter estimated from the top decile method}
Take aways: 
\begin{itemize}
    \item Clearly RT estimates are not a 1:1 match with choice estimates
    \item However, there is useful information in RTs
\end{itemize}

\subsection{Summary}
\begin{itemize}
    \item Response times alone can reveal strength of preference in controlled lab settings
    \item These results once again support the idea that value-based decisions are made from preferences constructed at the time of choice.
\end{itemize}
\subsection{Do people use information present in response times?}
\begin{itemize}
    \item There are various pieces of data showing that they do
    \item E.g. the length of time between an interview and job offer
    \begin{itemize}
        \item This interval could carry information about the strength of the employer's preference for the applicant
        \item This extra information can influence the applicant's decision to accept the offer
        \begin{itemize}
            \item Assumption: employees prefer to work at a firm that highly values them
        \end{itemize}
    \end{itemize}
    \item Becker et al (2010) find that job applicants are more likely to accept a job offer if it is delivered quickly (contolling for ex post employee performance ratings) 
    \item Van de Calseyde et al (2014) provide similar evidence in a laboratory setting where decision times are exogenously manipulated.
    \item From a theoretical perspective, if response times (RTs) reveal an agent's private information, then many economic environments will contain richer information structures than are typically modeled.
\end{itemize}

\subsection{RTs reveal private information in information cascades}
\begin{itemize}
    \item Experimental Design
    \begin{itemize}
        \item There is an uncertain state of the world (binary probability = 0.5)
        \item Each subject (n = 8) receives a private conditionally independent signal
        \item Subjects sequentially provide a prediction about the state of the world that everyone coming after them can observe
        \item Finally, the state becomes public to all
        \begin{itemize}
            \item Correct predictions pay 1 dollar
            \item Incorrect predictions earn 0 dollars
        \end{itemize}
    \end{itemize}
    \item The first person in the game has only their signal
    \item The second person has their signal and the first signal
\end{itemize}

\subsection{Key manipulation is the presence or absence of RT information}
\begin{itemize}
    \item Participants entered their predictions within a 10 second window.
    \item The prediction was only shown after 10s regardless of how soon the subject responded.
    \item Two conditions: in one condition, participants only saw the decisions of the previous subjects. In the other, they saw the decisions and the response times.
\end{itemize}


\subsection{Information cascades}
\begin{itemize}
    \item Suppose that 
    \begin{itemize}
        \item Player 1 sees A
        \begin{itemize}
            \item signals A
        \end{itemize}
         \item Player 2 sees B
         \begin{itemize}
             \item infers that the state is A with 0.5 probability
             \item Signals A
         \end{itemize}
         \item Player 3 sees B
         \begin{itemize}
             \item infers that the state is A with 0.66 probability
             \item Signals A
         \end{itemize}
    \end{itemize}
    \item This triggers an information cascade, with players 4-8 adopting the same logic and selecting action A regardless of their own private signals
    \item The normative prediction in such games is 
    \begin{itemize}
        \item If one state of the world has 2 net decisions in its favor
        \item Then all subjects should choose this state of the world
        \item It is optimal for all participants to cease their belief updating at this point
    \end{itemize}
\end{itemize}

\subsection{Predictions for adding RT information}
\begin{itemize}
    \item if a previous subject's RT is "long," then she likely has private information that conflicts with the preceding signals
    \item Do participants use RT information to break out of information cascades?
\end{itemize}
\subsection{Do participants use RT information to break out of information cascades}
Slide 41 graph x axis are the conditions and y axis is following private signal percentage.
\begin{itemize}
    \item RTs are long/short if they are above/below the median RT of 2.03 seconds
    \item Data are restricted to positions 4-8 and restricted to trials in which the private signal does not match the previous move
    \item They didn't tell people what RT meant
\end{itemize}
\subsection{RT information increases payoffs}
\subsection{Conclusion}
\begin{itemize}
    \item Study participants can infer conflict and private information from response time information without explicit instructions to do so
\end{itemize}
\subsection{Applying the DDM to value-based choice}
Clithero 2018. Food choice task. In the first stage: participants are shown one food and asked to give a yes or no answer to the question "would you like to eat this at the end of the study?" People are just responding without RT constraints but regardless they answer very quickly. The answers were fitted using a DDM or Logit methods. The aim is to predict binary choices when two foods are shown in the second task. The DDM produces the same sigmoid curve but it uses RTs in addition to outcomes to make a more precise estimate.
\subsection{Could the DDM generate better out-of-sample predictions about choice than traditional logistic regression models?}
\subsubsection{Notes}
\begin{itemize}
    \item The predictions derived from the DDM should be better than hose frmo a logit when trained on finite datasets
    \begin{itemize}
    \item When the mean RT curve is steep, the probability of choice curve is flat, when the mean RT curve is flat, the probability of choice curve is steep. Hence, they are complimentary.
        \item Especially when choice probabilities are around 0.25 or 0.75
    \end{itemize}
\end{itemize}
\subsection{Observed results for the DDM}
\begin{itemize}
    \item Fits to Yes/No Task
    \item Fits to predictions about choices and RTs in the 2-alternative forced choice task
\end{itemize}
\subsection{DDM vs Logit predictions for the 2AFC}
DDM is better overall. Page 48, for data above the 45 degree line, DDM is better. It is especially better where the logit curve is flatter.
\subsection{Combining attention influences and response time}
The more you look at an item, the more you value it and are likelier to buy it. We will incorporate this into the RT model.
\subsection{Greater fixation sensitivity leads to worse choices}
Fixation sensitivity:= change in slope
\\People who are more likely to fixate their attention are less likely to choose their subjective best option.
\subsection{Combining attention influences and response times}
\subsection{Response times in the wild}
\begin{itemize}
    \item eBay recently produced a dataset with all exchanges for listings created from June 2012 to June 2013. The dataset consists of millions of bargaining exchanges
    \item Cotet and Krajbich test if RTs from eBay sellers follow the patterns predicted by sequential sampling models of constructed preferences
\end{itemize}
\subsection{Accept and Reject RTs are proportional to $\frac{p1}{p0}$}
\subsection{Generality across goods}
This is true for a large variety of goods
\subsection{Experience}
Sellers show the same pattern of RTs across levels of experience
\subsection{Summary}
\begin{itemize}
    \item Response times are useful for
    \begin{itemize}
        \item Researchers trying to estimate/understand strengths of preference
        \item Individuals interacting with one another
    
    \end{itemize}
    \item Response times carry information for
    \begin{itemize}
        \item Decisions mad in controlled laboratory settings within seconds
        \item The pattern also appears to hold in real life as well
        \begin{itemize}
            \item Data from eBay sellers
            \item Other potential domains: Political endorsements, IPOs, returning phone calls or texts, etc
        \end{itemize}
    \end{itemize}
\end{itemize}
\section{Social Preferences and Economic Choice}
\subsection{Outline for the notes}
\begin{itemize}
    \item Models of social preferences
    \item Empirically measuring social preferences
    \item Neural substrates of social preferences
    \item Associations between hormones and social preferences
\end{itemize}
\subsection{Social Preferences}
\begin{itemize}
    \item Social preference theories try to incorporate some or all of the concepts listed below into models of choice:
    \begin{itemize}
        \item Altruism
        \item Fairness and inequity aversion
        \item Reciprocity
        \item Group welfare
    \end{itemize}
\end{itemize}
\subsection{Models of social preferences}
\begin{itemize}
    \item Models of social preferences assume that people are generally self-interested but also concerned about the payoffs of others
    \item Three types of models
    \begin{itemize}
        \item Inequality aversion
        \item Social welfare
        \item Reciprocity
    \end{itemize}
\end{itemize}
\subsection{Inequality aversion}
\begin{itemize}
    \item Inequality aversion models assume that people are averse to unequal outcomes
    \item The strength of this aversion to inequality may or may not be allowed to differ in advantageous vs disadvantageous contexts depending on the model
\end{itemize} 
\subsection{Fehr-Schmidt model (1999)}
\begin{itemize}
    \item Subtract weighted payoff difference from own payoff
    \item Allows for different weighting or discount factors in advantageous vs disadvantageous domains
    \item In multiplayer games, the largest inequality is implemented
\end{itemize}
\[U_{A}(\Pi^{A}, \Pi^{B} = \Pi^{A} - \beta(\Pi^{A} - \Pi{B}), if \Pi^{A} > \Pi^{B})\]
\[U_{A}(\Pi^{A}, \Pi^{B} = \Pi^{A} - \alpha(\Pi^{B} - \Pi{B} ,  if \Pi^{A} < \Pi^{B})\]
$\Pi^{A}$:=Payoff for self
\\$\Pi^{B}$:=Payoff for other
\\$\beta$:= Advantageous inequality aversion
\\$\alpha$:= Disadvantageous inequality aversion

\subsection{Social welfare models}
\begin{itemize}
    \item Social-welfare models assume people like to increase social surplus, caring especially about helping those with low payoffs
    \item Explains case where people chose to reduce the level of their own payoff if it will increase the sum of payoffs to all members
    \item Say option 1 pays you 3 and the other 5 and option 2 pays you 2.8 and the other 8. In this case, most would choose option 2, even though  it increases inequality and decreases your welfare. This cannot be explained by the F-S model.
\end{itemize}
\subsection{Charness and Rabin (2002)}
\begin{itemize}
    \item Includes parameters for reciprocity
    \begin{itemize}
        \item Reciprocity models assume that the desire to raise or lower others' payoffs depends on how fairly those others are behaving
    \end{itemize}
    \item Formulation is same as the Fehr-Schmidt model in advantageous situation if the other has not "misbehaved"
    \item Different from Fehr-Schmidt model in disadvantageous situation
    \begin{itemize}
        \item includes preferences for overall welfare
    \end{itemize}
    \item Payoff for self is denoted as B
  \item  The parameters ρ, σ, and Θ capture various aspects of social preferences
\begin{itemize}
    \item inequality averse preferences (σ < 0 < ρ < 1) mean that utility for B increases with πB and
decreases with the difference πB − πA.
\item σ < 0 assumes disutility for πA when πB < πA
\item competitive preferences (σ ≤ ρ < 0) mean that the utility for B increases as πB increases
relative to πA
\item narrowly self-interested preferences (σ = ρ = 0) mean that the utility for B depends only on
πB
\item social welfare preferences (0 < σ ≤ ρ ≤ 1) mean that utility for B increases with πB and πA.
\end{itemize} 
\end{itemize}

\subsection{Notes}
Different models of social preferences incorporate different motivations for other-regarding preferences
\begin{itemize}
    \item Inequality aversion
    \item Social welfare
    \item Reciprocity
\end{itemize}
\subsection{Empirically measuring social preferences}
\begin{itemize}
    \item Very brief overview of two common lab paradigms:
    \begin{itemize}
        \item Dictator game
        \begin{itemize}
            \item Measures altruism, generosity, and inequity aversion
        \end{itemize}
        \item Ultimatum game
        \begin{itemize}
            \item Proposer: Inequity aversion and beliefs about expectations
            \item Responder: Inequity aversion and reciprocity
        \end{itemize}
    \end{itemize}
\end{itemize}

\subsection{Dictator game}
\begin{itemize}
    \item Player A (dictator) can decide how much money (or any good) to split between herself and Player B (recipient)
    \item It could be a free or restrictive dictator game (dictator is restricted to a few given choices)
    \item The outcome is exactly the split that the dictator decides on
\end{itemize}
\subsection{Dictator game}
\begin{itemize}
    \item Prediction for purely self-interested agent = give zero
    \item Typical findings as reported by Levitt and List (2007) JEP:
    \begin{itemize}
        \item More than 60$\%$ of dictators give a positive amount of money with the mean being 20$\%$ of the endowment
    \end{itemize}
    \item By design, the dictators don't see the other person, don't know the person.
\end{itemize}
\subsection{Ultimatum game}
\begin{itemize}
    \item Player A (proposer) can decide how much money (or any good) to split between herself and Player B (responder)
    \item The responder can accept the split or reject it and then both players get nothing
    \item Dictator choice can still be motivated by altruism, generosity, or fairness but must also consider reciprocity.
    \item The responder's actions influenced by fairness and reciprocity preferences
    \item Predictions for purely self-interested agents:
    \begin{itemize}
        \item Proposer: give zero or minimum positive amount
        \item Responder: indifferent to zero, accept any positive offer
    \end{itemize}
    \item Typical findings as reported by Levitt and List (2007) JEP:
    \begin{itemize}
        \item Majority of proposer offers in the range of 25-50$\%$. Few below 5$\%$
        \item Responders frequently reject offers below 20$\%$
        \end{itemize}
\end{itemize}
\subsection{Modified Ultimatum game}
\begin{itemize}
    \item Removing reciprocity preferences
    \begin{itemize}
        \item The responder's actions influenced by fairness, but not reciprocity because player 1 did not act.
        
    \end{itemize}
\end{itemize}
\subsection{Notes}
We can isolate different motivations that people have by making them play both the dictator and ultimatum game. We can isolate their pure social preferences in the dictator game, and see how they adjust their preference with the ultimatum game.
\begin{itemize}
    \item Different games measure different motivations in social interactions
    \item Pure altruism and fairness are measured by unidirectional interaction
    \item Reciprocity is measured by bidirectional interactions
\end{itemize}
\subsection{Neural substrates of social preferences}
There is a large degree of individual variance in social preferences for fairness, altruism, reciprocity, etc. for example (Slide number 21). We are wondering how the variability in the histogram could relate to brain  structure and function.
\subsection{A restricted binary dictator game}
The dictators have two options in the fMRI. They are restricted, since choosing more options would make the subject move more and hurt the image. One option is a fairer split than the other.
\\There are two trials: advantageous and disadvantageous. In the advantageous trial, in both options, you will earn more, however, in one option, you will earn vastly more than the other person, where in the other, your payoffs will be more similar. It is the vice versa for the disadvantageous trial.

\subsection{No correlation between advantageous and disadvantageous preference parameters}
The lack of correlation suggests that preferences may differ between advantageous and disadvantageous contexts
\\So there is some difference between how you make these decisions between the two cases.

\subsection{Stability of preferences}
\begin{itemize}
    \item Studies on social/risk/time preferences have shown that preferences of an individual are relatively stable across time within domains
\item Could brain structure -which is relatively stable- support stable social preferences? So rather than looking at brain function, these authors will try to analyze the stucture of the brain.
\end{itemize}

\subsection{Measuring brain structure with voxel based morphometry}
Take a high resolution structural image of the brain. Use a computer algorithm to separate white matter and gray matter. Then, normalize and smooth the image. Aggregate the subjects and apply GLM.

\subsection{Grey matter density in right TPJ correlates with advantageous altruism}
The more grey matter you have in this region, the more you are willing to accept the cost for making an altruistic act.
\\Interestingly, density in this region does not correlate with other parameters such as disadvantageous altruism, positive reciprocity, and negative reciprocity.

\subsection{Social preferences in charitable donations}
This result seems to be in-line with another study on charitable donations and social preferences.
\\Experiment: On each trial you are shown an image and a title of a particular charitable donation and you are asked how much of your 100 dollars would you like to give to this cause. If you give some money, the experimenters will match your donations. In the second case, you are forced to donate a certain amount to the charity, regardless of your preferences. 
\\The idea is to compare trials where you actually need to compute how much you want to give to where you are forced to donate but still probably have bottom-up reactions to the image used for the cause.
\subsection{Donation amounts correlate with vmPFC activity}
The more you give, the stronger the activity there. When we take the intersection of Donation amount and food purchases, we see that vmPFC has an overlap between the two actions.

\subsection{TPJ activity is also associated with willingness to give to charity}
A measure of your willingness to give to charity is positively correlated with activity in the TPJ.
\subsection{Inhibitory brain stimulation via TMS over the TPJ increases selfish behavior}
Soutschek study conducted with a modified dictator game. Unlike other dictator games, participants knew some of the other people they played with, as they gave a list of family members or friends to the experimenters. The subjects could also be paired with random people too. There is a social distance scale between the pairs from 1-100. The family members or friends don't even know you are doing this task if you don't inform them, but the experimenters will actually pay them if you are paired with them since you gave the experimenters a list.
\\There are two conditions: In condition B, you either get 100 CHF or a 75-75 split between you and the person who is X social distances away from you.
\\In condition A, you are shown a delay of the payment first, and then you get an amount that you can take today.
\\Choices are modeled with a hyperbolic discount function
\[SV_{delay} = \frac{V_{delay}}{1 + k_{delay} \times D_{delay}}\]
\[SV_{social} = \frac{V_{social}}{1 + k_{social} \times D_{social}}\]
parameter k:= how much you will discount future payoffs 
D:= actual delay
\subsection{Results of the Study}
In both intertemporal and interpersonal conditions, the TMS lowers your discount rate.
\subsection{Why test temporal discounting and social preferences in the same experiment?}
\begin{itemize}
    \item Hypothesis: both decisions involve theory of mind and/or perspective taking
    \begin{itemize}
        \item Social decisions: take perspective of another person
        \item Intertemporal decisions: take perspective of your future self
    \end{itemize}
\end{itemize}

\subsection{Classic test for theory of mind (usually for children)}
Theory of mind: you have the ability to realize that your mind differs from another agent's mind.
\\A classic test: the Sally Anne test.
\subsection{Testing perspective taking after TPJ stimulation}
The experimenters are going to make you change your perspective to another person's perspective.
\\How many dots is the person able to see? Usually people don't make mistakes but with TPJ they do make a statistically significant higher number of errors.

\subsection{Brain stimulation (TMS) over the TPJ decreases perspective taking}
\begin{itemize}
    \item Across participants perspective taking errors were correlated with
    \begin{itemize}
        \item Temporal discounting 
        \item Social discounting
    \end{itemize}

    
\end{itemize}

 \subsection{vmPFC structural integrity also impacts social choices}
 Brain damage examination will try to answer this again, as TMS can't usually target this region.
 \subsection{vmPFC damage alters social choices}
 For the dictator game:  For people with damage to the vmPFC, the offers to the other individual is significantly lower compared to no damage. 
 \\For the ultimatum game: People without brain damage would offer more points than they demand. However, vmPFC would demand more than they are offered.
 \subsection{vmPFC damage alters social choices}
 \begin{itemize}
     \item vmPFC damage is associated with
     \begin{itemize}
         \item more individualistic behavior in the Dictator game
         \item No "cushion" for stricter fairness environment by others in the Ultimatum game
     \end{itemize}
 \end{itemize}

 \subsection{Notes}
 \begin{itemize}
     \item Large individual variance in generosity, fairness, altruism preferences
     \item Individual differences in brain structure and function of TPJ and vmPFC are associated with behavioral differences
 \end{itemize}
 \subsection{Reciprocity in the Ultimatum game}
 We are investigating what might cause you to reject an offer.
 \\Experiment: Play Ultimatum game against human subjects and a computer. Decide whether or not to accept or reject offer by those partners.
 \subsection{Results}
 Lower rejection rate against a computer
 \subsection{Neural response to unfair offers}
 Activity in a range of brain regions. However, dlPFC is activated significantly. The more activity in that region, the less likelier you will accept an offer. But again, this just a correlation. 
 \subsection{Causal role of dlPFC in UG with human partners}
 We can investigate the causal role of dlPFC activity by stimulation
 \\Inhibition of right dlPFC by TMS increase acceptance of unfair offers
 \\However, it doesn't change fairness ratings
 \subsection{No effect of right dlPFC in UG with computer partners}
 TMS doesn't significantly change behavior when the partner is a computer rather than a human being
 \\Computers aren't viewed as being unfair
 \subsection{Combined TMS+fMRI in the Ultimatum game}
 Want to investigate if there is an influence in the brain somewhere else when TMS inhibits the right dlPFC.

 \\As expected, TMS reduces activity in the stimulated region
 \\Interestingly, another area was influenced. TMS to rDLPFC also reduced activity in the vmPFC
 \subsection{Why does the association with vmPFC matter?}
 \begin{itemize}
     \item We have already seen that vmPFC represents subjective values for a wide range of goods
     \begin{itemize}
         \item Primary rewards
         \item Secondary rewards
         \item Moral values, donations to charity
         \item Another person's temporal discounting functions
     \end{itemize}
     \item Social preferences may be influenced by computations in specific areas of the brain, but if they are ultimately represented in vmPFC activity, then maybe they aren't qualitatively different from any other preference.
 \end{itemize}
 \subsection{Sample question}
 Similar brain structures are used to compute/implement social preferences compared to non-social choices- TRUE
 \subsection{dlPFC and Norm Compliance for proposers in the Punishment Game}
 Two conditions in this article: Dictator transfers and punishment transfers.
 Ultimatum game can be modified to become a punishment game, where the receiver can punish the sender by using monetary units from his own endowment, which would be multiplied by 5 and subtracted from the sender, resulting in a -Y MU penalty for the receiver and a -5Y penalty for the sender.
 \subsection{dlPFC and Norm Compliance in the Proposer}
 Average transfer rate in the Punishment condition is much higher than the dictator case. Results from slide 55.

\subsection{Brain activity}
Regions more active in the sanction enforced norm compliance condition are given on slide 56.

\subsection{Right dlPFC activity correlates with the average difference between Pun and Control transfer amounts.}
More dlPFC activity means higher  transfer difference between the punishment and the control conditions
\subsection{A causal role for right dlPFC in Norm Compliance}
Changing the brain activity by TMS in the dictator and punishment game. If they use inhibitory TMS on right dlPFC for the dictator game, there is less transfer than sham (no affect) and the excitatory TMS conditions. If they use inhibitory TMS on right dlPFC for the punishment game, there is more transfers than no stimulation and the excitatory stimulation conditions.
\subsection{dlPFC and Norm compliance in the proposer}
TMS did not change fairness ratings or expectations about anger or punishment
\subsection{Social and nonsocial contexts differ}
Nonsocial= computer
\subsection{Notes}
\begin{itemize}
    \item Perceived intention plays a key role in reciprocal social interaction
    \begin{itemize}
        \item Remember the different behavior with computer partners
    \end{itemize}
    \item The right dlPFC plays a causal role in making and accepting offers in Ultimatum game
    \item Inhibition of the right dlPFC changes
    \begin{itemize}
        \item proposal and rejection rates
        
    \end{itemize}
    \item doesn't affect reports of perceived unfairness
\end{itemize}
\subsection{Questions}
\begin{itemize}
    \item If choices and ratings can be changed by TMS independently, which one should we focus on?
    \item Can we completely write off the self-report ratings because they are not incentivized?
\end{itemize}
\subsection{Why reject UG offers}
\begin{itemize}
    \item Previous behavioral studies show that perceived fairness intention plays a role in rejection of unfair offer in Ultimatum game (computer fairness is perceived as high, which is why rejection rates were much lower)
    \item TMS experiments show that there is a dissociation between perceived fairness and actual rejection
    \item However, detection of unfairness $\neq$ Rejection of offer
\end{itemize}
\subsection{Impunity game}
Set up the same as the Ultimatum game, but the outcome of rejection differs.
\\Accept: Bot payoffs as proposed
\\Reject: Proposer keeps his proposed amount but responder gets nothing
\begin{itemize}
    \item Standard version-proposer informed of rejection
    \item Private version - proposer not informed
\end{itemize}
\subsection{Result}
Impunity game: Substantial rejection in both impunity and private impunity games
\begin{itemize}
    \item Reciprocity motivations can not fully explain rejection in Ultimatum game
    \item Speculation: rejection may be driven in part by  a desire to maintain one's self image.
\end{itemize}
\subsection{Hormones and social behavior}
Hormones have complex, widespread, context-dependent effects on physiology and behavior
\begin{itemize}
    \item Examples of context dependence:
    \begin{itemize}
        \item Dosage (studies ofthen use very high doses, which is not always generalizable to real life)
        \item Circadian rhythm
        \item Developmental stage
        \item Cultural or social context
    \end{itemize}
    \item Punchy headlines like "Hormone H causes behavior B" are, at best, incomplete stories
    \begin{itemize}
        \item The same is true for most things in economics or finance too
        \begin{itemize}
            \item Causal effects depend on initial conditions "dosage"
        \end{itemize}
    \end{itemize}
\end{itemize}

\subsection{Oxytocin and Testosterone examples}
These two hormones have a long history of being featured in high profile papers that link them to aspects of social behavior.
\subsection{Hormones and social behavior}
NoE
Oxytocin
\begin{itemize}
    \item Is a neuropeptide synthesized in hypothalamic neurons
    \item has a central role in regulating social approach and attachment behaviors in many non-human mammals
    \begin{itemize}
        \item Mother - infant bonding
        \item Adult pair bonding in monogamous mammals
    \end{itemize}
    \item Non-mammals have hormones with similar chemical structure
    \item The full body of literature indicates that the effects of oxytocin strongly depend on individual and contextual factors
\end{itemize}

Testosterone
\begin{itemize}
    \item Well-known as a sex hormone produced in the testes and ovaries
    \begin{itemize}
        \item Also produced in the adrenal glands
        \item Can be synthesized in the brain too
        
    \end{itemize}
    \item Many of the effects of systemic testosterone in the brain occur after it has been converted to estradiol
\end{itemize}
\subsection{Testosterone and social status}
Rather than promoting aggression per se, testosterone seems to promote actions that signal social status
\begin{itemize}
    \item In non-human animals, social status often signaled through aggression
    \item Humans have more ways of signaling social status
\end{itemize}
 \subsection{Testosterone and social status}
 Nave et al 2018.
\begin{itemize}
    \item Nave et al randomized male participants to a double-blind RCT
    \begin{itemize}
        \item 125 received a single dose of testosterone
        \item 118 received placebo
    \end{itemize}
    \item Two Tasks:
    \begin{enumerate}
        \item Decide between clothes from different brands
        \begin{itemize}
            \item Brands differed in their association with social rank
        \end{itemize}
        \item Rate attitudes about items
        \begin{itemize}
            \item Status enhancement
            \item Power enhancement
            \item Quality
        \end{itemize}
    \end{enumerate}
\end{itemize}
\subsection{Experiment timeline and manipulation check}
Survey in the morning and hand scan first. Then gel and T-loading period. Then behavioral tasks and then payout.
\\They will sample the amount of testosterone to make sure that the T didn't dramatically get lower over time.
\subsection{Task 1 Results}
People who had testosterone highly preferred brands with higher social rank significantly more than the no-T condition; however, both groups gave similar quality preferences.
\\Researchers specifically disassociated status and quality so that there wouldn't be a confound

\subsection{Task 2}
Only for goods that emphasized status there was a statistically significant different between the two groups with high-T preferring higher status goods.

\subsection{Hormones}
Question: Does oxytocin cause feelings of affiliation, trust, and prosocial behavior?
\\Answer: That depends on the animal, context, and your definition of prosocial.

\\Question: Does testosterone cause aggressive social behavior or violence?
\\Answer: That depends on the animal and the context

\subsection{Take home message}
Robust main effects of any single hormone, within physiologically plausible doses, on something as complex as social behavior are very unlikely
\\Hormones do influence social behaviors, just in complicated ways we don't fully understand yet

\section{Strategic Behavior}
\subsection{Game Theory}
Game theory is about how people interact
\begin{itemize}
    \item Originally developed to explain how intelligent/rational/emotionless agents should behave
    \item More recently used to model how average people actually behave
\end{itemize}
\subsection{What type of interactions}
\begin{itemize}
    \item Tennis players serving left or right
    \item Bakeries lowering prices at the end of the day
    \item Haggling in the marketplace
\end{itemize}
\subsection{Game Theory}
Components
\begin{itemize}
    \item Multiple players
    \item Each player has multiple actions
    \item Each possible combination of actions yields an outcome
    \item Each outcome yields different payoffs for each player
\end{itemize}
Nash Equilibra
\begin{itemize}
    \item Outcomes where no player can increase her own payoff by changing her action while keeping the other player's action constant
\end{itemize}
\subsection{Assumptions}
\begin{itemize}
    \item Rationality (best response)
    \begin{itemize}
        \item Given a player's belief about what the other player(s) will do, her action maximizes payoff
    \end{itemize}
    \item Common knowledge
    \begin{itemize}
        \item Everyone knows that everyone is rational and has fully thought through the game
    \end{itemize}
    \item Already in equilibrium
    \begin{itemize}
        \item No learning or out of equilibrium play
    \end{itemize}
\end{itemize}
If we deviate from one of these conditions, we can't compute NE
\subsection{Empirical problems with rationality or best response}
\begin{itemize}
    \item In experiments, we often see subjects playing "close" to equilibrium but not quite in equilibrium
    \item Many subjects choose the optimal action while others choose the second best action, fewer choose the third best, and so on
    \item Suggests a probabilistic choice process
\end{itemize}
\subsection{Alternative models that relax assumptions of Nash Equilibrium}
Quantal Response Equilibrium (QRE) 
\\Cognitive Hierarchy (CH)
\subsection{Quantal Response Equilibrium (QRE)}
\begin{itemize}
    \item QRE relaxes "Best response" while maintaining common knowledge and the equilibrium concept
    \item Rather than best responding to others' actions, each player "better responds" by choosing the best response with probability P1, the second best with probability P2 < P1, the third best response with probability P3 < P2
    \item Agents will still choose the best option with the highest probability but you don't HAVE TO
    \item Each player also knows that the other players are better responding (common knowledge) and so are better responding to a distribution of actions and not a single action
\end{itemize}
\subsection{Logit QRE}
Players choose their actions according to probabilities given by:
\[P_{ij} = \frac{\exp{\lambda EU_{ij}(P_{-i}}}{\sum_{k} \exp{\lambda EU_{ik}(P_{-i})}}\]
where $P_{ij}$ is the probability of player i choosing strategy j
\\EU$_{ij}$ is the expected utility to player i of choosing strategy j given other players are playing according to the probability distribution P$_{-i}$
\\k is the number of actions in the game
\\ $\lambda$ is the weighting parameter. Notice that as $\lambda$ $\rightarrow$ 0 players choose randomly, while as $\lambda$ $\righarrow$ $\infty$ players play in Nash Equilibrium
\subsection{Results}
$\lambda$ increases over time. This means that they are better responding.
\subsection{QRE Summary}
\begin{itemize}
    \item QRE provides a better fit of human behavior than Nash in some classes of games
    \begin{itemize}
        \item Especially in relatively simple games with a small number of players
        \item Behavior in more complex and/or large group games is often not fit well by QRE
        \item In many cases, there is evidence that the common knowledge assumption of QRE is not valid.
    \end{itemize}
\end{itemize}
\subsection{Problems with common knowledge}
\begin{itemize}
    \item Common knowledge is a strong assumption, which assumes that each player correctly knows the other players' strategies
    \item Often implausible, especially in complicated or unfamiliar games
    \item Data often show different distributions of choices by different subjects and this violates the equilibrium assumptions of QRE
\end{itemize}

\subsection{Beauty Contest}
In the beauty contest game, everyone writes a number from 0-100 and your goal is to pick 2/3 of the average. QRE predicts that most would pick 0 and the relative frequencies would stably fall but that is not what we see due to a lack of common knowledge. Most people choose around 33-36
\subsection{Explanations}
\begin{itemize}
    \item Notice that we cannot explain this behavior using QRE or other equilibrium 
+noise models 
\begin{itemize}
    \item A rational player;s best response is always to choose low and so equilibrium-like behavior will always peak at 0.
    \item It must be that players have different beliefs about what the other players will choose
    \item We must relax the common knowledge assumption!
\end{itemize}
\end{itemize}

\subsection{Cognitive Hierarchy (CH) model}
\begin{itemize}
    \item Let's assume that different players put different levels of thought into their decision
    \item Assume discrete steps of thinking where each level indicates one more iteration of analysis of the game
    \begin{itemize}
        \item Level 0: These players do not understand the game and so choose randomly
        \item Level 1: These players believe that everyone else that are playing are Level 0's and best-respond to that belief
        \item Level 2: These players realize that there is likely some mixture of Level 1's and Level 0's and best-respond
\item  Level K: believe that there is a mixture of Level 0-K-1 players and best-respond accordingly

    \end{itemize}
\end{itemize}

\subsection{Why only up to K-1?}
\begin{itemize}
    \item The intuition behind the model is that each "best response" calculation takes effort and players are labeled by the number of calculations they make
    \item Level 0's make no calculation and choose randomly
    \item Level 1's only make 1 calculation, so they can only best-respond to one strategy, namely the Level 0 strategy
    \begin{itemize}
        \item They can't best-respond to other Level 1's as well because that would require a second calculation, turning them into a Level 2 player
    \end{itemize}
\end{itemize}

\subsection{Beauty contest with learning: Guesses start to move toward zero over repeated rounds}
\section{Summary}
Most people do not play strategic games like completely rational, emotionless geniuses
\\People display various levels of sophistication in incorporating the actions of others into their strategies
\\Remember: its not just games! We have examples from tennis, politics, etc...
\subsection{How does the brain implement strategic choices?}
\subsection{Neuroimaging example I}
Replicating the beauty contest in the fMRI machine. They are playing against other humans or computers in two different conditions. They don't know anything about the other human, but, they will be notified of the computer's strategy. Computer always chooses uniformly.
\\There is another calculation task to see if your mental math is good enough to be able to calculate means and medians for the beauty contest task.

\subsection{Human vs Computer choice}
mPFC and TPJ are regions that have been repeatedly implicated in "mentalizing" tasks that require individuals to consider the beliefs of other.
\subsection{mPFC activity and strategic behavior}
The more you engage the mPFC, the closer you get to the winning number in the human opponent condition.
\subsection{Neuroimaging Example II}
Work vs Shirk game
Two roles in the game: Employer and Employee. If the employee is working and the employer doesn't inspect, the employer gets 100 and the employee gets 0. If the employee is working and the employer inspects, the employee gets 50. If the employee is shirking, and the employer doesn't inspect, the employee gets 50 and the employer gets 0, and if the employee is shirking and the employer inspects, the employer gets 25 and the employee gets 0.
\subsection{Hampton et al, tested an idea similar to CH}
\begin{itemize}
    \item Is behavior best captured by:
    \begin{enumerate}
        \item Simple temporal difference reward learning
        \item A 'fictitious play' model where the subject chooses the best response based on the past history of the opponent
        \begin{itemize}
            \item For example, the employee might work more often after being inspected several times
            \item An 'influence' model where subjects consider that their own actions will influence the opponent
            \begin{itemize}
                \item The employer doesn't inspect after inspecting twice in a row under the belief that the previous inspections will cause the worker to work
            \end{itemize}
        \end{itemize}
    \end{enumerate}
\end{itemize}
\subsection{Influence model has the best to the choice data}
\subsection{Good match between model predictions and subject's choices}
The probability of work/shirk and inspect/no inspect is predicted well by the influence model
\subsection{Fitting model predictions to brain activity}
There are very few regions in the brain that correlate with the simple RL model
\\Fictitious model also has little correlations but
\\Influence model has way more correlates in the brain compared to the other two

\subsection{Influence better than RL}
There are certain regions that correlate significantly with certain parts of the brain.
\subsection{Switch vs Stay predictions}
The three models also make different predictions about the expected reward, and therefore BOLD signal on stay vs switch trials
\subsection{Switch vs Stay Predictions}
Expected Value Difference = Switch - Stay
\\Neural activity matched the influence model in mPFC
\begin{itemize}
    \item Both RL and fictitious play will most likely "stay" after a reward and "switch" after a non-reward. mPFC implicated
    \item The influence model has a higher incentive to switch even after receiving a reward
    \begin{itemize}
        \item Expected reward signals associated with a specific action do not necessarily increase after the receipt of a reward when taking into consideration the influence that an action exerts on the opponent's strategy
    \end{itemize}
\end{itemize}
\subsection{What about at outcome}
At the outcome phase, you are told the outcome of that trial and you can update your strategy then
\subsection{Activity correlated with TPJ in the update signal}
It was found that higher activity in the TPJ was correlated with the update portion of the influence equation
\subsection{Individual differences in strategy correlate with mPFC (again)}
Remember that influence model is equal to the fictitious play plus the impact of self on other's actions and could be interpreted as higher level reasoning similar to levels in CH
\subsection{Testing the causal role of TPJ in strategic choice using TMS}
Scanned players have a training phase and then are split into two Groups: Placebo group that gets scanned for an irrelevant part of the brain (so that their experimental conditions are similar) and the experimental condition group whose rTPJ gets scanned. They then play against Human opponents outside of the scanner who were trained individually.
\subsection{Behavioral Results}
The rTPJ stimulation group:
\begin{itemize}
    \item Switches actions less often
    \item Is more predictable from one trial to the next
    \item Has a lower influence parameter (k)
\end{itemize}

\subsection{TMS reduces the influence update signal in right TPJ}

\subsection{Once again, dmPFC activity correlates with model sophistication}
TMS over the right TPJ decreases its functional association with the dmPFC.
This again suggests that TPJ is very important for strategic behaviors regarding thinking about what other people might be doing.
\\One question we have is that, how social is the TPJ? Does it give similar results for non-human interactions or opponents?

\subsection{Neural differences between groups}
Single card poker game in which the high card wins
\\Played versus computer and human opponents
\\All subjects bet on low cards more than 10$\%$ of the time.
\subsection{Opponent characteristics}
The same human opponent played against all participants
\begin{itemize}
\begin{itemize}
    \item His base pay was ten dollars
    \item He received one bonus of five dollar in-game earnings were sufficiently large
    \item He received a second bonus of five dollars for helping his call rate between 45$\%$ and 55$\%$ over the course of the experiment 
\end{itemize}
\item The choice to bluff or fold for the computer opponent was made by random selection with an equal probability of a bluff or fold on each trial
\end{itemize}

\subsection{Using brain data to predict behavior in a strategic game}
\begin{itemize}
    \item To predict bet/fold choices, the brain was divided into 55 separate anatomical regions
    \item Predictions were made using multivariate analysis techniques using different combinations of these 55 regions
    \item They are going to try to find unique combinatorial advantage. Meaning, when a region is included and excluded in the analysis, how strong are the predictions?
\end{itemize}
On the graph on slide 61, we see the computer opponent UCP measures on the x axis and Human opponent UCP on the y axis.
\\TPJ improved performance more for human opponents compared to computer opponents. The authors refer to this as a "social bias."
\\Social bias in TPJ predictive power is stronger in subjects who considered the human partner to be the better opponent compared to subjects who believe computers were better than or equal to human opponents

\subsection{Notes}
Neuroimaging techniques reveal that the patterns of brain activity underlying strategic choices partially overlap with
\begin{itemize}
    \item Altruistic choices
    \item Simple choices for the individual alone

\end{itemize}
Areas involved in reasoning about others' beliefs seem to contribute to higher order thinking in strategic games
\subsection{Strategic behavior in bargaining}
In this example: Feedback is hidden. Page 65 diagram. Buyer gets value v, sends suggestion s. Seller receives suggestion s, submits price p. If p $\leq$ v, DEAL. Seller earns p, Buyer v-p. If p is greater than v, NO DEAL. Both get payoff 0
\subsection{Strategic behavior in bargaining}
\begin{itemize}
    \item The tradeable object has no value to either player if a trade does not occur
    \item However, if a trade does occur, each player prefers a sale price that favors them
    \begin{itemize}
        \item Buyers prefer lower prices
        \item Sellers prefer higher prices
    \end{itemize}
    \item This misalignment of incentives implies that the only equilibrium solution of the one-round version of this game is for no information transfer to occur
    \item The buyer should "babble" and send suggestions with no informative relationship to her private value
    \item The seller should ignore this suggestion and set a price of either 5 or 6 (to maximize the expected revenue)
    \item However, this is the mutually optimal solution only if both players believe that the other is also playing in equilibrium
    \item Babbling is only optimal if the seller is in fact ignoring buyer suggestions
    \item Ignoring buyer suggestions is only optimal if they contain no meaningful information
    \item In reality, players' beliefs about what others are likely to do are often not accurate
    \item Therefore, descriptive  models of belief formation and adjustment will be relevant
    \item Models such as cognitive hierarchy predicts the existence of different behavioral types based on the depth to which participants model their opponents
\end{itemize}
\subsection{How do Buyers actually behave?}
We can break down the people who play this game into three groups:
\\– Incrementalists (blue) send suggestions that are highly correlated with their true value
\\– Strategists (red) send suggestions that are negatively correlated with value. Strategists appear similar to
incrementalists and thus reap the surplus from high-value trials.
\begin{itemize}
    \item This is strategically logical. If the item is low value and the strategist sends in a high value and the seller plays accordingly, the deal won't take place. If the item is high value and the strategist sends a low value and the seller plays accordingly, they will reap the benefits.
\end{itemize}
\\– Conservative buyers (green) play closest to an economically rational actor and reveal no information about their
value with their suggestions
\\Histograms on slide 71 showing suggestion frequencies for a single incrementalist and a single strategist. Note that from the perspective, the two look indistinguishable.
\subsection{Traits between groups}
\\No difference in IQ or socioeconomic status
\\Incrementalists earn less than Strategists and conservatives from the experiment.
\subsection{The dlPFC is more active in strategists compared to the other two groups}
\subsection{Right TPJ activity varies as a function of value for strategists, but not conservatives or incrementalists}

\section{Memory and decision-making}
\subsection{Types of memory according to retention time}
\begin{itemize}
    \item Sensory memory (milliseconds)
    \item Working and short-term memory (seconds to minutes)
    \item Long-term memory (minutes to years)
\end{itemize}
\subsection{Working memory (WM)}
A limited capacity storage and manipulation system 
\begin{itemize}
    \item Used to maintaining information over a short time (seconds) in order to manipulate it
    \item Very limited capacity (4-9 single items at one time)
    \item Capacity varies across individuals and domains but is relatively stable within a given individual
\end{itemize}
Active manipulation of information distinguishes working memory from short-term memory (passive storage)
\subsection{Long term memory (LTM)}
Can be separated into categories
\begin{itemize}
    \item Declarative: knowledge that you can consciously access
    \begin{itemize}
        \item Episodic: memory for episodes/experiences in your life. Example: I was at the birthday party
        \item Semantic: facts about the world. Example: Monte Rosa is the tallest mountain in CH.
    \end{itemize}
    \item Nondeclarative memory: knowledge without conscious access
    \begin{itemize}
        \item Riding a bike, kicking a ball
    \end{itemize}
\end{itemize}

\subsection{WM and LTM sub-categories are at least partially distinct}
Studies of patients with brain lesions show that damage to specific brain regions leads to deficits in specific forms of memory.
\subsection{The famous case of HM}
Clear evidence for the functional localization of declarative long-term memory
\\Both his hippocampi were surgically removed
\\After surgery he could not form new memories
\\He had anterograde amnesia

\subsection{HM could still form new non-declarative memories}
E.g., he could learn new tasks such as mirror drawing after practicing
\begin{itemize}
    \item He did not consciously know that he had gained these skills
\end{itemize}
\subsection{Memory, imagination and simulation}
Fact: anterograde amnesiacs such as HM also have difficulty imagining the future
\\Hypothesis: The purpose of memory is to guide current and future decisions and actions
\begin{itemize}
    \item There is little evolutionary benefit to just remembering the past because we can't change it
    \item There are obvious benefits to learning from the past to inform or improve subsequent behavior
    \item Being able to imagine or simulate novel combinations of goods experienced separately in the past could help decision-makers generalize knowledge to new situation
\end{itemize}
\subsection{Evidence that preferences are generalized via memory}
Memories are a source of information for constructing preferences about goods that we have experienced in the past
\\Values spread across things that are associated with one another in memory
\subsection{Preference by association}
In past lectures, we discussed how temporal difference models can explain the way we learn about va;ue through repeated experiences of reward or punishment
\\Wimmer and Shohamy tested if this type of learning can generalize across stimuli that are associated with one another in memory
\\Study took place in three phases
\begin{enumerate}
    \item Association phase: They would show either a picture of a face, body part, or scene and present that with an abstract fractal image
\item Reward phase: Only shown the abstract images. Some will predict a reward, some won't.
\item Decision phase: The subjects would then get two mandatory choices: They would choose between a reward abstract image and a no-reward abstract fractal image and then they would choose between two scenaries, one of which was associated earlier with the reward image.
\end{enumerate}
\subsection{Association phase}
Six unique S1 stimuli were always followed by the same S2 circle
\begin{itemize}
    \item S1 images were initially rated as neutral
    \item Two S1 images were drawn from each category
    
\end{itemize}
Participants were not told about the associations between S1 and S2.
\begin{itemize}
    \item Task was to respond to occasional inverted faces, body part, or scene images
\end{itemize}
Each S1-S2 pair was shown 10 times in a pseudo-random order
\\Faces, body-parts and scenes reliably drive activity in different brain regions
\\This fact is used to test for reactivation of S1 stimuli in the subsequent reward phase
\subsection{Reward phase}
Only S2 stimuli are shown (never S1). 
\\One of the two S2 stimuli paired with each category
of S1 (face, body part, scene) was assigned as
S2+, the other S2-
\begin{itemize}
    \item S2+ were followed by reward 81$\%$ of the time
    \item S2- were followed by neutral outcomes 100$\%$
of the time
\end{itemize} 
Participants had to press a button for every image.
\begin{itemize}
    \item One button ”collected” dollar bills
\item They had to press a different button for all
other stimuli
\end{itemize}
Participants were informed that they might notice predictive associations between each circle stimuli (S2 and reward or neutral outcomes)
\subsection{Decision Phase}
Participants chose between two S1 or two S2 stimuli
\\Were told to pick the one they thought would be
more likely to win 1 dollar.
\begin{itemize}
    \item No feedback
    \item 4 repeats of each pairing

\end{itemize}
In the absence of any spread of reward,
\begin{itemize}
    \item participants should be equally likely to choose any of the never-rewarded S1 images
    \itembrain activity during the prior reward phase should be unrelated to these decisions.
\end{itemize}
However, if reward spreads and biases decisions,
\begin{itemize}
    \item then participants should be biased toward choosing S1 images that were previouslyassociated with the S2 rewarded images more often.
    \begin{itemize}
        \item “decision bias” = the tendency to chose S1+ items over S1– items,
    \end{itemize}
    \item decision bias should be related to hippocampus activity during the reward learning
phase.
\end{itemize}
\subsection{Results}
Participants chose S2+ stimuli more often than S2-
\\The level of decision bias varied substantially across participants and stimuli
\begin{itemize}
    \item Mean preference for S1+
\end{itemize}

The authors use the variability in decision bias to test hippocampal activity
\\They find more hippocampal activity during the reward phase S2 stimuli who's associated S1 image would later have a strong decision bias
\\Decision bias did not relate to reported memory accuracy
\subsection{Hippocampal activity was compared during the Reward phase not the decision phase}
The idea was that seeing S2 should activate representations of the associated S1

\subsection{Testing reactivation of S1 during the Reward Phase}
Remember that faces, body parts, and scenes activate different portions of the brain's visual processing system
\\This gives the authors a means of testing for reactivation of S1 representations
\\Also, remember that S1 is not shown during the Reward phase they are testing in
\subsection{Reactivations are stronger for high-bias than low-bias S1 images}
Hippocampus plays an important role in connecting the information where it is stored in the brain but may not be the place that actually stores the memory. The more the S1 encoding regions are used, the more bias you will have.
\subsection{Conclusion}
Activation of memory associations between S2 and S1 during the Reward phase seems to facilitate the generalization of reward learning across related stimuli

\subsection{Combining memories to evaluate new things}
We often need to decide between goods or actions that we have no direct experience with
\\Can we simulate possible values for new things based on memories of previous outcomes?

\subsection{Preplay}
Decision making involves 'preplay' of potential outcomes in the brain
\begin{itemize}
    \item Multiple studies show this for 
    \begin{itemize}
        \item rodents navigating familiar mazes to reach reward
        \item Humans making spatial and non-spatial decisions over familiar items
    \end{itemize}
    \item Can humans use preplay to represent novel goods
\end{itemize}
\subsection{Repetition suppression}
Neuronal populations respond less to a stimulus when it is repeated within a short time frame
\\Less neural response == less fMRI BOLD signal

\\Thus, if novel goods are represented as a combination of familiar goods in the brain, BOLD signals should be lower for a novel combined good when it is preceded by one of its components

\\It is not just about items it is also how much you like the items as well

\\Experiment will create combinations of food to make a novel good with different familiar component goods. They will also present characters with the foods to create associations. They want to control for any visual associations between the component and the novel item.
\\13 novel goods created from the combinations of two familiar food types
\\Novel goods were not previously been tasted together
\\Two examples are shown here: avocado and raspberry smoothie and tea jelly.
\subsection{Learning prior to scanning}
The goal is to test for overlap in memories of simulations, not visual characteristics
\\Train to associate components and combinations with abstract symbols
\\Accuracy = 97.8 percent after training
\subsection{Two tests in the scanner}
Choose between novel goods
\\Imagine sensory properties of novel goods

\subsection{Chosen values are correlated with vmPFC and dmPFC}
\subsection{vmPFC and the 
hippocampus show repetition suppression}
If you have the same chosen value in a row, you would have less signal the latter time
\subsection{The extent of the suppression effect is related to a good's value}
The more valuable the novel goods are, the higher the repetition suppression in both the vmPFC and the hippocampus
\\The mechanistic reason for this relationship between a good's value and repetition suppression across components and combinations is as yet, unknown.
\subsection{Suppression between components and combinations disappears with experience}
The authors tested another group of participants in the same manner, but first gave the one sample of the novel goods.
\\Suppression was less when the items were familiar as the subjects already tasted it. Hence, potentially, they stopped treating it as a novel imaginary combination item but rather another item that was tried.
\\Once a novel food is experienced, its representation may be distinct from its component parts.
\begin{itemize}
    \item E.g., we don't think of ice cream as frozen milk, sugar, salt, water, and air bubbles
\end{itemize}

\subsection{Conclusion}
Preplay simulations of outcome values occurs in humans brains
\begin{itemize}
    \item Mediated by structures that are known to play a key role in memory formation and recall
\end{itemize}
\begin{itemize}
    \item Hippocampal damage and value-based choice
\end{itemize}
–Does damage to the hippocampus impair value-based choices relative to perceptual
choices?
\begin{itemize}
    \item If the hippocampus is used to recall and predict values, then damage there should
impair value-based choices
\item Perceptual choices are based on current sensory information, not remembered or
simulated values
\begin{itemize}
    \item Should not be impaired by hippocampal damage

\end{itemize}
\end{itemize}
We have hippocampal damaged patients: Two groups: value based choices such as food choices and perceptual choices.
\\Value based choices
\begin{itemize}
    \item Bid on 60 food items in a BDM auction
    item Choose between pairs of foods with a range of value differences
    \item Pictures of the foods were shown on the screen
    \begin{itemize}
        \item Memory not required for knowing the choice set
        \item may be required for evaluation and comparison
    \end{itemize}
\end{itemize}
Perceptual task
\begin{itemize}
    \item Judge if there are more yellow or blue dots
    \item Dots flicker in and out
    \begin{itemize}
        \item Degree of flickering determines difficulty
    \end{itemize}
\end{itemize}
\subsection{Perceptual Decisions results}
Indeed, perceptual decisions were okay in both groups, and response times were also pretty normal. 

\subsection{Value-based Decisions Results}
Probability of correct answer was less for amnesiacs. Worse accuracy compared to healthy controls
\\Reaction times were higher for amnesiacs
\subsection{Amnesic patients show altered accuracy/speed trade offs for value-based choices}
Even though they can see the food images on the screen and know that they are choosing between an apple and a banana, due to the damage to their hippocampus, impairs their ability to accurately choose, based on their own subjective values, which of the two items are better.
\subsection{Summary}
Result: Value construction and comparison is impaired following hippocampal damage
\\Conclusion: memory and simulation systems are important for constructing precise
values at the time of choice
\section{Emotions and Decision Making}
\subsection{Outline of this lecture}
\begin{itemize}
    \item Definitions and key ideas regarding emotion
    \item Emotions as specific motivators
    \item Neurobiology of emotion and the limbic system
\end{itemize}

\subsection{What is emotion?}
Colloquially, emotion is used to refer to all aspects of affective experience
\\However, in component process theories of emotion and affect the term "emotion" is proposed to reflect the discrete response to an external or internal event that entails a range of synchronized features, including:
\begin{itemize}
    \item subjective experience,
    \item expression
    \item bodily response
    \item action tendencies
\end{itemize}
Emotions may involve all or a subset of the features listed on the previous slide
\\The key is that this subset be expressed in a relatively synchronized, temporally discrete manner
\subsection{Emotion vs Mood}
In contrast to emotions as synchronized, discrete responses to an event, moods are diffuse affect states characterized primarily by subjective feelings that are relatively enduring and generally low intensity
\\However, moods and emotions are not mutually exclusive and can be initiated by the same event
\begin{itemize}
    \item For example, suppose you find out you did well on an exam, or your favorite football club wins a game.
    \begin{itemize}
        \item You become happy directly after the outcome and might also maintain a good mood for the rest of the day even when not thinking about the exam or game
    \end{itemize}
\end{itemize}
\subsection{Common Emotions}
\\Positive vs Negative
\\Positive: Happiness
\\Negative: Fear, sadness, anger, disgust

\\Surprise: can be positive or negative
\subsection{Emotion feature 1: Subjective experience}
Feelings are the consciously accessible and therefore most prominent characteristics of
emotions, but they are only one component of emotion.
\\It is argued that emotions can occur without a change in subjective experience (see
Öhman et al ., 2000; Funayama et al ., 2001 ; Winkielman et al ., 2005 ).
\begin{itemize}
    \item This debate is not fully resolved
\item Regardless, it is true that we can measure aspects of emotion without asking about
subjective experience.
\end{itemize}

\subsection{Emotion feature 2: Expressions}
Charles Darwin, and others after him, suggested that the patterned facial expressions of
emotion evolved for two functions:
\\ The first being as a means of social communication to allow conspecifics to both benefit
from the emotional reactions of others., such as fear to a threatening stimulus or disgust
to a noxious stimulus, and to determine the intent of others, such as smiling in
appeasement or anger when threatening.
\subsection{Facial expressions send clear signals}
\\Anger: I am upset and may cause you harm
\\Fear: There is something dangerous nearby
\\Disgust: Don't eat this!
\\Happy: Everything is fine and I approve of what you are doing
\subsection{Emotion feature 2: Expressions}
\\The second proposed function of facial expressions is to alter the perceptual experience
in adaptive ways by changing the facial configuration.
\begin{itemize}
    \item  widening the eyes to obtain more visual information in fear
    \item restricting the nasal passages to limit olfactory sensation in disgust
\end{itemize}
\subsection{Emotional expressions prime the body for relevant actions}
Fear motivates the acquisition of information in order to escape threat, while disgust reduces sensory exposure to aversive stimuli.

\subsection{Emotions prime the body for relevant actions
}Changes in the subjective visual field - a fearful face allows you to see more. Even though when  not feeling the emotion, when you mimic the expression, you get the benefits.
\\Disgust reduces your sensory input allowance
\\Changes in saccade  velocity- The eyes move faster when making a fearful face, even when the individual is not actually frightened
\\Changes in inspiration capacity- a fearful expression allows more airflow to the lungs


\subsection{Emotional feature 3: Bodily response}
This is often referred to as the fight or flight response
\\Emotions elicit changes in hormones, heart-rate, and skin conductance
\\They also promote behaviors like freezing and enhacned startle responses
\begin{itemize}
    \item Very useful for studying affective responses in animal models. Remember the classical or Pavlovian conditioning studies we discussed before
\end{itemize}
\subsection{Emotion feature 4: Action tendencies}
Approach vs avoid
\begin{itemize}
    \item People and animals tend to move away from threats and disgusting objects
    \item However, they often move towards stimuli that elicit happiness
\end{itemize}
\subsection{Emotions as specific motivators}
Emotions are often separated into positive and negative or aversive domains.
\\It is commonly assumed that one aspect of decision making is to try and increase
positive emotions at the time of outcome
\\However, emotions can influence decision making even if they are incidental to the
choice
\\Not all negative emotions have the same influence on choices. Each negative emotion is
associated with a specific ‘adaptive’ behavioral response
\\People may sometimes chose to experience negative emotions if the behavior they
motivate is useful

\subsection{Using emotion productively}
\begin{enumerate}
    \item Do people choose to experience “negative” emotions if they believe that they will aid
performance on a specific task?
\item Do emotions actually improve performance?
\end{enumerate}

\subsection{Choosing to be afraid}
Method
\begin{itemize}
    \item Subjects given the opportunity to recall emotional memories under different conditions
    \item All subjects were told that they would be playing computer games in the next part of the study, but the types and goals of these games differed
\end{itemize}
    Method, computer game descriptions
    \begin{itemize}
        \item Avoidance games: Avoid flying monsters trying to eat you or sneak across enemy terrain
        \item Approach games: find and grab money as quickly as possible or build a theme park
        \item Confrontation: Avenge the murder of a spouse or fight an opponent
        
    \end{itemize}
Before the game, the subjects were asked how much they would like to experience an emotion, either fear, excitement, or anger, during these three aforementioned games
\\Approach goal: Excitement preferred
\\Avoidance goal: fear-inducing
Confrontational goal: anger inducing
\subsection{Goal dependent choice of emotion}
Different experiment: Tenant and landlord: collaborate (long term) and confront (short term)
\\Before interacting with the 2nd player (tenant) the landlords could choose from different emotion inducing
activities
\\Confrontation group got angry more, collaboration group was more happy

\subsection{Choices based on expected usefulness}
\subsection{Congruent emotions benefit performance}
Landlords who chose the anger inducing activities collected significantly more rent
\begin{itemize}
    \item Somewhat incentive compatible in that each player had a points payoff matrix based on amount  of rent collected, but these points did not change the cash payout
\end{itemize}

\subsection{Notes}
People will sometimes choose to experience negative or 'aversive' emotions if those emotions are expected to convey some behavioral benefit
\\Again, different negative emotions have different expected affects on decisions
\subsection{Incidental happiness and sadness have been reported to change temporal discounting rates}
Sadness reportedly increases impatience, happiness reportedly decreases impatience

\subsection{The happiness study didn't replicate}
Watching films didn't change TD values for people

\subsection{Study characteristics associated with replication measures}

\subsection{For sadness}
\\ Emotion induction using 3-min video clips
– Sadness: a clip about the death of a boy’s mentor (Gross & Levenson, 1995)
– Disgust: a clip about an unsanitary toilet (Lerner et al., 2004)
– Neutral: a clip about the Great Barrier Reef (Lerner et al., 2004)
\\ Following the videos participants wrote essays about experiencing sadness, disgust, or
their nightly activities (neutral). \\Emotion induction resulted in higher self-reported ratings of the targeted emotion

\subsection{Results}
Sadness did change temporal discount factors

\subsection{But why is that?}
Sadness makes the subjects more prone to having impatient thoughts, which alters their TD.

\subsection{Query theory predicts affects of thought order}
QT proposes that preferences are constructed, rather than pre-stored and immediately
retrievable
\\Construction happens in accordance with the answers to one or more internally posed
questions, or queries.
\\Query order depends on the structure of the choice situation or task, and can influence
retrieval of information, leading to different decisions.
\\The ordering of your items will decide which one you will prefer later.

\\Sadness seems to change the order of motivations you come up with for having something now or the future, which influences TD

\subsection{Sadness also appears to reduce patience for cigarettes}
Increases inhalation volume while smoking

\subsection{Sadness vs happiness influences on TD}
Does sadness have stronger influences on temporal discounting?
\begin{itemize}
    \item Hard to say based on one set of film clips (i.e., one form of emotion induction)
\begin{itemize}
    \item One film clip could induce stronger emotions than the other
\item Interpretation of the films may have changed after > 15 years
\end{itemize}
\item Thought processes induced by the film clips
\begin{itemize}
    \item Not measured for happiness
\item Sadness effects mediated by impatient thoughts and/or self-focus rather than negative
affect per se
\begin{itemize}
    \item The ”sad” clip deals with death (critical confound?)
\end{itemize}
\end{itemize}
\end{itemize}


\subsection{Emotions as motivators summary}
\\– Discrete motions have specific motivational properties. E.g., approach, avoid, engage, withdraw
– The effects of emotion on choices are driven, at least in part, by the behaviors they
motivate
\subsection{Neurobiology of emotion}

\subsection{Emotions are often mediated by the limbic system}
\subsection{We know that aversive, fear learning is mediated by the amygdala}
No amygdala in rats: no fear learning from shocks
\subsection{Emotional enhancement of memory is also linked to amygdala activity}
Amygdala activation predicts memory for emotional items in one study

\subsection{The Amygdala processes emotional signals}
Even subconsciously presented emotional signals increase amygdala activity

\\This might have something to do with the evolutionary response to detecting fear

\subsection{Trustworthiness judgements are also impaired by amygdala damage}
Approachability of faces can be misjudged
\\Trustworthiness: Even the faces with the least trustworthy faces are marked as trustworthy by amygdala damaged patients

\subsection{Take home message}Patients with bilateral amygdala lesions
(JM, SM, RH) rate negative faces as
more trustworthy and approachable than
healthy and brain damaged controls
\\Thus, not only is the amygdala involved
in processing emotion it also plays a role
in evaluating social others
\subsection{Another word of caution on reverse inference}
– While we know that emotions often involve brain structures such as the amygdala, we CANNOT
infer any specific emotion from the presence or absence of binsula, and ventral striatum,rain
activity.
– For some reason, people are especially tempted to make reverse inferences related to
emotional states.
– All three structures process information and have cognitive in addition to emotional processing.
\\These areas are not just active in emotions and will be active in other tasks. Their sole purpose isn't to process emotions
\\ The primary issue is that most brain regions are involved in multiple functions and
behaviors and increased activity in a specific region could mean many different
things.

\\Remember the Real vs Imagined movement, they look pretty similar